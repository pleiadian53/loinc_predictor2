{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions Prior to Using This Module \n",
    "\n",
    "1. Training data has been generated via Analyzer2 (or Analyzer, a predecessor version)\n",
    "   - Example input: <project_dir>/loinc_predictor/data/andromeda-pond-hepatitis-c-balanced.csv\n",
    "   \n",
    "   - Training data are generated in two formats \n",
    "     \n",
    "     a. raw \n",
    "     \n",
    "     b. encoded\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import DataFrame, Series\n",
    "import os, sys, re\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # action='once'\n",
    "\n",
    "# local modules\n",
    "from analyzer import load_data, save_data, load_performance\n",
    "import loinc as lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Target Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = 'hepatitis-c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Memo\n",
    "----\n",
    "1. medivo_test_result_type is a function of the following attributes: \n",
    "      \"meta_sender_name\",\n",
    "      \"receiving_organization_id\",\n",
    "      \"test_order_code\",\n",
    "      \"test_order_name\",\n",
    "      \"test_result_code\",\n",
    "      \"test_result_name\",\n",
    "      \"test_result_loinc_code\",\n",
    "      \"test_result_units_of_measure\"\n",
    "      \n",
    "\"\"\"\n",
    "from analyzer import sample_col_values\n",
    "from loinc import FeatureSet\n",
    "\n",
    "cat_cols = FeatureSet.cat_cols  # 22 vars\n",
    "cont_cols = FeatureSet.cont_cols  # e.g. age\n",
    "derived_cols = FeatureSet.derived_cols\n",
    "# ... ['count']  # other possible vars: test result n-th percentile, normalized test frequency\n",
    "\n",
    "target_cols = FeatureSet.target_cols  # ['test_result_loinc_code', ]\n",
    "\n",
    "# cardinality < 100\n",
    "low_card_cols = FeatureSet.low_card_cols # ['patient_gender', 'fasting', 'meta_sender_name' ]\n",
    "high_card_cols = FeatureSet.high_card_cols\n",
    "\n",
    "target_columns = cat_cols + cont_cols + target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load (Curated) Training Data\n",
    "\n",
    "note: Training data was saved prior to the variable encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(load_data) Loaded dataframe (dim=(1123499, 128)) from:\n",
      "/Users/barnett/Documents/work/loinc_predictor/data/andromeda-pond-hepatitis-c-balanced.csv\n",
      "\n",
      "(load) dim(df): (1123499, 128) | columns:\n",
      "['meta_package_key', 'input_filename', 'patient_date_of_birth', 'patient_gender', 'patient_state', 'patient_bill_type', 'diagnosis_codes', 'diagnosis_descriptions', 'laboratory_diagnosis', 'billing_diagnosis_codes', 'insurance_company_id', 'insurance_company_name', 'fasting', 'performing_organization_id', 'performing_organization_name', 'performing_organization_address_line_1', 'performing_organization_address_line_2', 'performing_organization_city', 'performing_organization_state', 'performing_organization_zip_code', 'analyzing_organization_id', 'analyzing_organization_name', 'analyzing_organization_address_line_1', 'analyzing_organization_address_line_2', 'analyzing_organization_city', 'analyzing_organization_state', 'analyzing_organization_zip_code', 'receiving_organization_id', 'receiving_organization_name', 'receiving_organization_address_line_1', 'receiving_organization_address_line_2', 'receiving_organization_city', 'receiving_organization_state', 'receiving_organization_zip_code', 'ordering_practice_name', 'ordering_practice_lab_account_name', 'ordering_practice_lab_account_number', 'ordering_practice_address_line_1', 'ordering_practice_address_line_2', 'ordering_practice_city', 'ordering_practice_state', 'ordering_practice_zip_code', 'ordering_provider_alternate_id_type', 'ordering_provider_alternate_id', 'ordering_provider_npi_number', 'ordering_provider_first_name', 'ordering_provider_last_name', 'ordering_provider_middle_initial', 'ordering_provider_suffix', 'ordering_provider_degree', 'ordering_provider_primary_specialty', 'ordering_provider_secondary_specialty', 'referring_practice_name', 'referring_practice_address_line_1', 'referring_practice_address_line_2', 'referring_practice_city', 'referring_practice_state', 'referring_practice_zip_code', 'referring_provider_alternate_id_type', 'referring_provider_alternate_id', 'referring_provider_npi_number', 'referring_provider_first_name', 'referring_provider_middle_initial', 'referring_provider_last_name', 'referring_provider_suffix', 'referring_provider_degree', 'referring_provider_primary_specialty', 'referring_provider_secondary_specialty', 'test_result_status', 'test_turnaround_time', 'test_order_code', 'test_order_name', 'test_result_code', 'test_result_name', 'test_result_loinc_code', 'test_result_value', 'test_result_range', 'test_result_abnormal_flag', 'test_result_reference_range', 'test_result_units_of_measure', 'test_result_comment_source', 'test_result_comments', 'test_priority', 'test_specimen_collection_volume', 'test_specimen_type', 'test_specimen_source', 'test_relevant_clinical_information', 'test_cpt_code', 'parent_test_order_code', 'parent_test_order_name', 'embedded_result_attached', 'total_amount_charged', 'total_amount_paid', 'test_transaction_datetime', 'test_specimen_draw_datetime', 'test_specimen_receipt_datetime', 'test_specimen_analysis_datetime', 'test_observation_datetime', 'test_observation_reported_datetime', 'result_copies_to', 'result_copies_type', 'panel_order_code', 'panel_order_name', 'parent_panel_order_code', 'parent_panel_order_name', 'unique_record_id', 'token1', 'token2', 'token3', 'token4', 'token5', 'token12', 'token13', 'token14', 'token15', 'datetime_of_processing', 'meta_package_source_file', 'meta_dict_orig', 'meta_dict_final', 'meta_ingestion_datetime', 'meta_original_filename', 'meta_sender_name', 'meta_sender_source', 'meta_sender_type', 'meta_sender_dataset', 'meta_sender_ver', 'medivo_test_result_type', 'count']\n",
      "\n",
      "[1] name: patient_gender => values: \n",
      "[('F', 616179), ('M', 504671), (nan, 2649)]\n",
      " ... mode: F\n",
      "[2] name: patient_state => values: \n",
      "[(nan, 143674), ('FL', 139043), ('CA', 134067), ('NY', 115446), ('GA', 89930), ('TX', 69887), ('PA', 37191), ('TN', 35498), ('NJ', 32575), ('AL', 28100)]\n",
      " ... mode: nan\n",
      "[3] name: patient_bill_type => values: \n",
      "[('PRIVATE INSURANCE', 462614), ('CLIENT', 165759), ('MEDICARE', 146383), (nan, 133604), ('MANAGE CARE FFS', 91297), ('MEDICAID', 41311), ('PI', 29702), ('MANAGE CARE CAP', 18350), ('CM', 17716), ('MC', 8905)]\n",
      " ... mode: PRIVATE INSURANCE\n",
      "[4] name: fasting => values: \n",
      "[(nan, 827207), ('Y', 144257), ('N', 74396), ('U', 65516), ('NOT FASTING', 8045), ('FASTING', 4078)]\n",
      " ... mode: nan\n",
      "[5] name: performing_organization_id => values: \n",
      "[(nan, 395205), ('BN', 17404), ('RN', 8886), ('CPLSW', 8838), ('SO', 4175), ('CB', 3979), ('TA', 3940), ('MB', 3560), ('SML', 3273), ('DA', 2469)]\n",
      " ... mode: nan\n",
      "[6] name: receiving_organization_id => values: \n",
      "[(16.0, 155390), (22.0, 84377), (1.0, 77507), (28.0, 77032), (nan, 61976), (14.0, 51604), (17.0, 50157), (15.0, 31130), (41.0, 30094), ('16', 27985)]\n",
      " ... mode: 16.0\n",
      "[7] name: test_result_status => values: \n",
      "[('F', 1025877), (nan, 66027), ('C', 27305), ('X', 4288), ('718868718781', 1), ('935780700030', 1)]\n",
      " ... mode: F\n",
      "[8] name: test_order_code => values: \n",
      "[('3100006399', 59541), ('2600010231', 49506), ('5100000747', 21751), ('35000', 16564), ('322000', 14597), ('3100005463', 13244), ('005009', 12232), ('2600007573', 11912), ('30031', 10332), ('6600010799', 9414)]\n",
      " ... mode: 3100006399\n",
      "[9] name: test_order_name => values: \n",
      "[('CBC (INCLUDES DIFF/PLT)', 86086), ('COMPREHENSIVE METABOLIC PANEL', 72426), ('PROTEIN ELECTROPHORESIS', 41620), ('DIFFERENTIAL, MANUAL', 25652), ('IRON AND TOTAL IRON BINDING CAPACITY', 17834), ('URINALYSIS, COMPLETE', 16786), ('Comp. Metabolic Panel (14)', 14648), ('HEPATIC FUNCTION PANEL', 12425), ('CBC With Differential/Platelet', 12235), ('CBC (Includes Diff/Plt)', 11454)]\n",
      " ... mode: CBC (INCLUDES DIFF/PLT)\n",
      "[10] name: test_result_code => values: \n",
      "[('25000210', 10456), ('35000705', 5816), ('86013635', 5614), ('25000000', 5381), (25016100, 5315), ('30002200', 5308), ('30002800', 5306), (25016200, 5292), ('30003000', 5193), ('30002400', 5165)]\n",
      " ... mode: 25000210\n",
      "[11] name: test_result_name => values: \n",
      "[('ALBUMIN', 12011), ('GLUCOSE', 11954), ('eGFR NON-AFR. AMERICAN', 10070), ('ABSOLUTE LYMPHOCYTES', 8992), ('INTERPRETATION', 8147), ('ABSOLUTE NEUTROPHILS', 7849), ('EOSINOPHILS', 6981), ('PROTEIN/CREATININE RATIO', 6951), ('ABSOLUTE EOSINOPHILS', 6535), ('HEMOGLOBIN A1c', 6421)]\n",
      " ... mode: ALBUMIN\n",
      "[12] name: test_result_value => values: \n",
      "[('DNR', 86777), (nan, 35215), ('NEGATIVE', 30172), ('NON-REACTIVE', 21483), ('0', 19682), (0, 12128), ('0.3', 10067), ('0.4', 7476), ('0.2', 6173), ('0.5', 5772)]\n",
      " ... mode: DNR\n"
     ]
    }
   ],
   "source": [
    "from analyzer import load_data, analyze_values\n",
    "\n",
    "input_file=f\"andromeda-pond-{cohort}-balanced.csv\"\n",
    "ts = load_data(input_file=input_file, warn_bad_lines=False)\n",
    "print(\"(load) dim(df): {} | columns:\\n{}\\n\".format(ts.shape, list(ts.columns))) \n",
    "# ... 'ts' at this point contains all variables\n",
    "\n",
    "# check feature values\n",
    "analyze_values(ts, cols=cat_cols, topn=10)  # topn: most common n feature values (and their counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformation\n",
    "note: patient_date_of_birth => age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2bfdfef806f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtTransformed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mto_age\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> age: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ts' is not defined"
     ]
    }
   ],
   "source": [
    "from transformer import to_age\n",
    "from analyzer import col_values\n",
    "# from loinc import FeatureSet\n",
    "\n",
    "tTransformed = False\n",
    "\n",
    "if not tTransformed: \n",
    "    to_age(ts)\n",
    "    values = col_values(ts, col='age', n=10)\n",
    "    print(\"> age: {}\".format(values))\n",
    "\n",
    "# datatime columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Features and Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_default = token_missing = 'unknown'\n",
    "token_other = 'other'\n",
    "\n",
    "if not tTransformed: \n",
    "\n",
    "    tCategorify = False\n",
    "    tDropHighMissing = False # drop columns with high rate of missing values\n",
    "    p_null = 0.9\n",
    "\n",
    "    # V = list(feature_lookup.keys())\n",
    "    V = cont_cols + cat_cols + derived_cols\n",
    "    L = target_cols\n",
    "    dfX = df[V]\n",
    "    dfy = df[L]\n",
    "\n",
    "    print(\"> Given features set:\\n{}\\n\".format(V))\n",
    "\n",
    "    assert np.sum(dfy[target_cols[0]].isnull()) == 0\n",
    "\n",
    "    # drop columns/vars with too many missing values \n",
    "    N = dfX.shape[0]\n",
    "    n_thresh = int(N * p_null)\n",
    "    nf0 = nf = dfX.shape[1]\n",
    "    fset0 = set(dfX.columns.values)\n",
    "\n",
    "    if tDropHighMissing: \n",
    "        dfX = dfX[dfX.columns[dfX.isnull().mean() < p_null]]\n",
    "        fset = set(dfX.columns.values)\n",
    "        nf = dfX.shape[1]\n",
    "        print(\"> Dropped n={} features:\\n{}\\n\".format(nf-nf0, fset0-fset))\n",
    "\n",
    "    fset = set(dfX.columns.values)\n",
    "    print(\"> Final feature set (nf={}):\\n{}\\n\".format(nf, fset))\n",
    "\n",
    "    # fill in missing values (also see default_values)\n",
    "    dfX.fillna(value=token_default, inplace=True)\n",
    "    #################################################\n",
    "    # Convert our three categorical columns to category dtypes.\n",
    "\n",
    "    cat_cols = [cat for cat in cat_cols if cat in dfX.columns]\n",
    "    cont_cols = [c for c in cont_cols if c in dfX.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import encode_vars \n",
    "from loinc import FeatureSet\n",
    "# high_card_cols = FeatureSet.high_card_cols\n",
    "\n",
    "encoder = None\n",
    "if not tTransformed: \n",
    "    nf0 = dfX.shape[1]\n",
    "    dfX, encoder = encode_vars(dfX, fset=cat_cols, high_card_cols=high_card_cols)\n",
    "    print(\"> After variable encoding we have dim(dfX): {} | nf: {} -> {}\".format(dfX.shape, nf0, dfX.shape[1]))\n",
    "    print(\"> New feature set:\\n{}\\n\".format(dfX.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyzer import encode_labels, summarize_dict, get_sample_sizes\n",
    "import collections, operator\n",
    "\n",
    "codebook={'pos': 1, 'neg': 0, '+': 1, '-': 0}\n",
    "\n",
    "if not tTransformed: \n",
    "    # verify\n",
    "    assert dfX.shape[0] == dfy.shape[0], \"> dim(dfX): {} | dfy.cols: {}\".format(dfX.shape, dfy.columns.values)\n",
    "\n",
    "    \n",
    "    # choose the one with a large sample size as 'positive'\n",
    "    col_label = 'test_result_loinc_code' # strings\n",
    "\n",
    "    topn = 5\n",
    "    sizes = get_sample_sizes(dfy[col_label])\n",
    "    # ... sizes: (loinc) label -> sample size\n",
    "    # print(\"> n(sizes): {}\".format(len(sizes)))  # 734 for cohort='hepatitis-c'\n",
    "\n",
    "    # Q: How many classes/codes have less than N instances? \n",
    "    N_low = 1000\n",
    "    n_low = sum(1 for l, c in sizes.items() if c < N_low)\n",
    "    print(\"> Low sample size classes | n={} (< {})\".format(n_low, N_low))\n",
    "\n",
    "    N_elow = 10\n",
    "    n_elow = sum(1 for l, c in sizes.items() if c < N_elow)\n",
    "    print(\"> Extreme low sample size classes | n={} (< {})\".format(n_elow, N_elow))\n",
    "\n",
    "    # Q: How many classes/codes were able to match the most enriched class in terms of sample size (e.g. 5707) -- by \n",
    "    #    taking in extra data from an external source? \n",
    "    eps = 10\n",
    "    n_matched = sum(1 for l, c in sizes.items() if c >= max_size-eps)\n",
    "    print(\"> n_matched: {} | max_size: {}\".format(n_matched, max_size))\n",
    "\n",
    "    # sort by values\n",
    "    sizes_sorted = sorted(sizes.items(), key=operator.itemgetter(1))\n",
    "    summarize_dict(sizes, topn=15, sort_=True)\n",
    "\n",
    "    print(\"> sizes: {}\".format(sizes.most_common(20)))\n",
    "    most_sample_sizes = sizes.most_common(topn)  # take(topn, sizes.items())\n",
    "    print(\"> Sample sizes | Top N={} codes:\\n{}\\n\".format(topn, most_sample_sizes))\n",
    "    least_sample_sizes = sizes.most_common()[:-topn-1:-1]\n",
    "    print(\"> Sample sizss | Last N={} codes:\\n{}\\n\".format(topn, least_sample_sizes))\n",
    "\n",
    "    # test\n",
    "    target = most_sample_sizes[0][0]\n",
    "    y = encode_labels(dfy, pos_label=target, codebook=codebook, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_tree, utils_sys, analyzer\n",
    "import collections\n",
    "from analyzer import balance_by_downsampling\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from loinc import TSet\n",
    "\n",
    "def get_sample_size(y, code_book={}):\n",
    "    if not code_book: code_book = TSet.code_book\n",
    "    counter = collections.Counter(y)\n",
    "    return (counter[codebook['neg']], counter[codebook['pos']])\n",
    "\n",
    "# data transformation\n",
    "col = 'test_result_loinc_code'\n",
    "X, y = dfX.values, dfy[col].values\n",
    "print(\"> dim(X): {}, sample(y): {}\".format(X.shape, np.random.choice(np.unique(y),20) ))\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler() # MinMaxScaler(), StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "n_fold = 5\n",
    "n_min = n_fold\n",
    "\n",
    "# to save performance data\n",
    "header = ['code', 'mean', 'std', 'n_pos']\n",
    "sdict = {h:[] for h in header}\n",
    "for code in loinc_set: \n",
    "    y_eff = analyzer.encode_labels(y, pos_label=code)\n",
    "    \n",
    "    n_neg, n_pos = get_sample_size(y_eff)\n",
    "    print(f\"> sample size | n0(+): {n_pos}, n0(-): {n_neg}\")\n",
    "    \n",
    "    if n_pos >= n_min: \n",
    "        # additional step to balance control sample size (in 1-vs-all, the 'other' class tends to be too large) \n",
    "        X_eff, y_eff = balance_by_downsampling(X, y_eff, method='multiple')\n",
    "        n_neg, n_pos = get_sample_size(y_eff)\n",
    "        print(f\"> sample size (after downsampling) | n(+): {n_pos}, n(-): {n_neg}\")\n",
    "        \n",
    "        # training + evaluation (default classifier: logistic regression)\n",
    "        scores = analyzer.eval_performance(X_eff, y_eff, model=None, cv=n_fold, random_state=53, verbose=1)\n",
    "        \n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores)\n",
    "        print(\"> average: {}, std: {}\".format(mean_score, std_score))\n",
    "    else: \n",
    "        print(\"> (positive) sample size too small, n={}\".format(n_pos))\n",
    "        mean_score = -1 \n",
    "        std_score = -1\n",
    "    sdict['code'].append(code)\n",
    "    sdict['mean'].append(mean_score)\n",
    "    sdict['std'].append(std_score)\n",
    "    sdict['n_pos'].append(n_pos)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# save performance dataframe\n",
    "df_perf = DataFrame(sdict, columns=header)\n",
    "df_perf = df_perf.sort_values(by=['mean', ]) # ascending=False\n",
    "analyzer.save_performnace(df, output_dir='result', output_file='', **kargs)\n",
    "\n",
    "cohort = 'hepatitis-c'\n",
    "output_dir = os.path.join(os.getcwd(), 'result')\n",
    "output_file = f\"performance-{cohort}-3.csv\" \n",
    "output_path = os.path.join(output_dir, output_file)\n",
    "df_perf.to_csv(output_path, sep='|', index=False, header=True)\n",
    "\n",
    "for code, score in zip(df_perf['code'], df_perf['mean']):\n",
    "    print(f\"[{code}] -> {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Memo\n",
    "---- \n",
    "1. performance plot\n",
    "\n",
    "   perplot: https://pypi.org/project/perfplot/\n",
    "\"\"\"\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from analyzer import load_performance\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(6, 20))\n",
    "sns.set_color_codes(\"pastel\")\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "# load performance data\n",
    "cohort = 'hepatitis-c'\n",
    "df_perf = load_performance(input_dir='result', cohort=cohort)\n",
    "print(\"> dim(performance matrix): {}\".format(df_perf.shape))\n",
    "\n",
    "# sort ~ performance scores \n",
    "# df_perf = df_perf.sort_values(by=['mean', ], ascending=False)\n",
    "\n",
    "header = ['code', 'mean', 'std', 'n_pos']\n",
    "codes = df_perf['code']\n",
    "n_codes = len(codes)\n",
    "scores = df_perf['mean']\n",
    "\n",
    "# some statistics\n",
    "score_high = 0.90\n",
    "score_low = 0.50\n",
    "\n",
    "codes_low_sz = df_perf.loc[df_perf['mean'] < 0]['code']\n",
    "codes_scored = df_perf.loc[df_perf['mean'] >= 0]['code']\n",
    "codes_high_score = df_perf.loc[df_perf['mean'] >= score_high]['code']\n",
    "assert n_codes == len(codes_low_sz) + len(codes_scored)\n",
    "\n",
    "print(\"1. Total number of codes: {} | n(low_sample): {}, n(scored):{}, n(high scored):{}\".format(n_codes, \n",
    "   len(codes_low_sz), len(codes_scored), len(codes_high_score)))\n",
    "r_scored = len(codes_scored)/(n_codes+0.0)\n",
    "rh = len(codes_high_score)/(n_codes+0.0)\n",
    "print(\"2. Fraction of scored codes: {}\".format(r_scored))\n",
    "print(\"3. Fraction of highly scored codes: {}\".format(rh))\n",
    "\n",
    "# Effective performance dataframe, ruling out those codes without scores (due to low sample sizes)\n",
    "df_eff = df_perf.loc[df_perf['mean'] >= 0.0]\n",
    "\n",
    "n_offset = 25\n",
    "df_topn = df_eff.sort_values(['mean', ], ascending=False).head(n_offset)\n",
    "df_botn = df_eff.sort_values(['mean', ], ascending=True).head(n_offset)\n",
    "# print(df_botn)\n",
    "\n",
    "# codes = [str(c) for c in df_botn['code'].values]\n",
    "# print('lower codes: {}'.format(codes))\n",
    "# scores = df_botn['mean'].values\n",
    "# print('scores: {}'.format(scores))\n",
    "\n",
    "# top n + bottom n\n",
    "dfe = pd.concat([df_topn, df_botn], ignore_index=True)\n",
    "dfe.sort_values(by=['mean', ], ascending=False, inplace=True)\n",
    "codes = [str(c) for c in dfe['code'].values]\n",
    "scores = dfe['mean'].values\n",
    "# print('lower(n)+higher codes(n): {}'.format(codes))\n",
    "# print('scores: {}'.format(scores))\n",
    "print(dfe)\n",
    "\n",
    "# sns.barplot(x=\"total\", y=\"abbrev\", data=crashes,\n",
    "#             label=\"Total\", color=\"b\")\n",
    "\n",
    "# --------------------\n",
    "# ax = sns.barplot(x='mean', y='code', data=df_botn)\n",
    "# print(\"-------------------------\\n\\n\")\n",
    "# print(\"> dtype: {}\".format(df_botn.dtypes))\n",
    "# print(df_botn.head(10))\n",
    "\n",
    "# dfe = dfe[['mean', 'code']]\n",
    "# dfe.plot(kind='bar')\n",
    "\n",
    "sns.barplot(x='mean', y='code', data=dfe, order=dfe['code'], # order has to be specified; even if already sorted!!!\n",
    "            label=\"LOINC\", color=\"b\", orient='h')\n",
    "\n",
    "# ax = sns.barplot(x='mean', y='code', data=df)\n",
    "\n",
    "# ax.set_xlabel('Fmax Score')\n",
    "# ax.set_ylabel('LOINC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
