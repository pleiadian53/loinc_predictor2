{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions Prior to Using This Module \n",
    "\n",
    "1. Training data has been generated via Analyzer2 (or Analyzer, a predecessor version)\n",
    "   - Example input: <project_dir>/loinc_predictor/data/andromeda-pond-hepatitis-c-balanced.csv\n",
    "   \n",
    "   - Training data are generated in two formats \n",
    "     \n",
    "     a. raw \n",
    "     \n",
    "     b. encoded\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import DataFrame, Series\n",
    "import os, sys, re\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # action='once'\n",
    "\n",
    "# local modules\n",
    "from analyzer import load_data, save_data, load_performance\n",
    "import loinc as lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Target Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = 'hepatitis-c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Memo\n",
    "----\n",
    "1. medivo_test_result_type is a function of the following attributes: \n",
    "      \"meta_sender_name\",\n",
    "      \"receiving_organization_id\",\n",
    "      \"test_order_code\",\n",
    "      \"test_order_name\",\n",
    "      \"test_result_code\",\n",
    "      \"test_result_name\",\n",
    "      \"test_result_loinc_code\",\n",
    "      \"test_result_units_of_measure\"\n",
    "      \n",
    "\"\"\"\n",
    "from analyzer import sample_col_values\n",
    "from loinc import FeatureSet\n",
    "\n",
    "cat_cols = FeatureSet.cat_cols\n",
    "cont_cols = FeatureSet.cont_cols  # e.g. age\n",
    "derived_cols = FeatureSet.derived_cols\n",
    "# ... ['count']  # other possible vars: test result n-th percentile, normalized test frequency\n",
    "\n",
    "target_cols = FeatureSet.target_cols  # ['test_result_loinc_code', ]\n",
    "\n",
    "# cardinality < 100\n",
    "low_card_cols = FeatureSet.low_card_cols # ['patient_gender', 'fasting', 'meta_sender_name' ]\n",
    "high_card_cols = FeatureSet.high_card_cols\n",
    "\n",
    "target_columns = cat_cols + cont_cols + target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load (Curated) Training Data\n",
    "\n",
    "note: Training data was saved prior to the variable encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(load_data) Loaded dataframe (dim=(1101980, 128)) from:\n",
      "/Users/barnett/Documents/work/loinc_predictor/data/andromeda-pond-hepatitis-c-balanced.csv\n",
      "\n",
      "(load) dim(df): (1101980, 128)\n",
      "[1] name: patient_gender => values: \n",
      "[('F', 603447), ('M', 495872), (nan, 2661)]\n",
      " ... mode: F\n",
      "[2] name: patient_state => values: \n",
      "[(nan, 141099), ('FL', 135943), ('CA', 131372), ('NY', 113619), ('GA', 87442), ('TX', 68794), ('PA', 36562), ('TN', 34938), ('NJ', 31877), ('AL', 27541)]\n",
      " ... mode: nan\n",
      "[3] name: patient_bill_type => values: \n",
      "[('PRIVATE INSURANCE', 450083), ('CLIENT', 162543), ('MEDICARE', 142836), (nan, 135202), ('MANAGE CARE FFS', 89843), ('MEDICAID', 40432), ('PI', 29138), ('MANAGE CARE CAP', 17871), ('CM', 17302), ('MC', 8737)]\n",
      " ... mode: PRIVATE INSURANCE\n",
      "[4] name: fasting => values: \n",
      "[(nan, 813502), ('Y', 140158), ('N', 72298), ('U', 63512), ('NOT FASTING', 8429), ('FASTING', 4081)]\n",
      " ... mode: nan\n",
      "[5] name: performing_organization_id => values: \n",
      "[(nan, 399127), ('BN', 17223), ('CPLSW', 9100), ('RN', 8797), ('SO', 4045), ('CB', 3872), ('TA', 3867), ('SML', 3397), ('MB', 3383), ('DA', 2437)]\n",
      " ... mode: nan\n"
     ]
    }
   ],
   "source": [
    "from analyzer import load_data, analyze_values\n",
    "\n",
    "input_file=f\"andromeda-pond-{cohort}-balanced.csv\"\n",
    "df = load_data(input_file=input_file, warn_bad_lines=False)\n",
    "print(\"(load) dim(df): {}\".format(df.shape))\n",
    "\n",
    "# check feature values\n",
    "analyze_values(df, cols=cat_cols, topn=10)  # topn: most common n feature values (and their counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformation\n",
    "note: patient_date_of_birth => age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import to_age\n",
    "from analyzer import col_values\n",
    "# from loinc import FeatureSet\n",
    "\n",
    "tTransformed = False\n",
    "\n",
    "if not tTransformed: \n",
    "    to_age(ts)\n",
    "    values = col_values(ts, col='age', n=10)\n",
    "    print(\"> age: {}\".format(values))\n",
    "\n",
    "# datatime columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Features and Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_default = token_missing = 'unknown'\n",
    "token_other = 'other'\n",
    "\n",
    "if not tTransformed: \n",
    "\n",
    "    tCategorify = False\n",
    "    tDropHighMissing = False # drop columns with high rate of missing values\n",
    "    p_null = 0.9\n",
    "\n",
    "    # V = list(feature_lookup.keys())\n",
    "    V = cont_cols + cat_cols + derived_cols\n",
    "    L = target_cols\n",
    "    dfX = df[V]\n",
    "    dfy = df[L]\n",
    "\n",
    "    print(\"> Given features set:\\n{}\\n\".format(V))\n",
    "\n",
    "    assert np.sum(dfy[target_cols[0]].isnull()) == 0\n",
    "\n",
    "    # drop columns/vars with too many missing values \n",
    "    N = dfX.shape[0]\n",
    "    n_thresh = int(N * p_null)\n",
    "    nf0 = nf = dfX.shape[1]\n",
    "    fset0 = set(dfX.columns.values)\n",
    "\n",
    "    if tDropHighMissing: \n",
    "        dfX = dfX[dfX.columns[dfX.isnull().mean() < p_null]]\n",
    "        fset = set(dfX.columns.values)\n",
    "        nf = dfX.shape[1]\n",
    "        print(\"> Dropped n={} features:\\n{}\\n\".format(nf-nf0, fset0-fset))\n",
    "\n",
    "    fset = set(dfX.columns.values)\n",
    "    print(\"> Final feature set (nf={}):\\n{}\\n\".format(nf, fset))\n",
    "\n",
    "    # fill in missing values (also see default_values)\n",
    "    dfX.fillna(value=token_default, inplace=True)\n",
    "    #################################################\n",
    "    # Convert our three categorical columns to category dtypes.\n",
    "\n",
    "    cat_cols = [cat for cat in cat_cols if cat in dfX.columns]\n",
    "    cont_cols = [c for c in cont_cols if c in dfX.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import encode_vars \n",
    "from loinc import FeatureSet\n",
    "# high_card_cols = FeatureSet.high_card_cols\n",
    "\n",
    "if not tTransformed: \n",
    "    nf0 = dfX.shape[1]\n",
    "    dfX = encode_vars(dfX, fset=cat_cols, high_card_cols=high_card_cols)\n",
    "    print(\"> After variable encoding we have dim(dfX): {} | nf: {} -> {}\".format(dfX.shape, nf0, dfX.shape[1]))\n",
    "    print(\"> New feature set:\\n{}\\n\".format(dfX.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyzer import encode_labels, summarize_dict, get_sample_sizes\n",
    "import collections, operator\n",
    "\n",
    "codebook={'pos': 1, 'neg': 0, '+': 1, '-': 0}\n",
    "\n",
    "if not tTransformed: \n",
    "    # verify\n",
    "    assert dfX.shape[0] == dfy.shape[0], \"> dim(dfX): {} | dfy.cols: {}\".format(dfX.shape, dfy.columns.values)\n",
    "\n",
    "    \n",
    "    # choose the one with a large sample size as 'positive'\n",
    "    col_label = 'test_result_loinc_code' # strings\n",
    "\n",
    "    topn = 5\n",
    "    sizes = get_sample_sizes(dfy[col_label])\n",
    "    # ... sizes: (loinc) label -> sample size\n",
    "    # print(\"> n(sizes): {}\".format(len(sizes)))  # 734 for cohort='hepatitis-c'\n",
    "\n",
    "    # Q: How many classes/codes have less than N instances? \n",
    "    N_low = 1000\n",
    "    n_low = sum(1 for l, c in sizes.items() if c < N_low)\n",
    "    print(\"> Low sample size classes | n={} (< {})\".format(n_low, N_low))\n",
    "\n",
    "    N_elow = 10\n",
    "    n_elow = sum(1 for l, c in sizes.items() if c < N_elow)\n",
    "    print(\"> Extreme low sample size classes | n={} (< {})\".format(n_elow, N_elow))\n",
    "\n",
    "    # Q: How many classes/codes were able to match the most enriched class in terms of sample size (e.g. 5707) -- by \n",
    "    #    taking in extra data from an external source? \n",
    "    eps = 10\n",
    "    n_matched = sum(1 for l, c in sizes.items() if c >= max_size-eps)\n",
    "    print(\"> n_matched: {} | max_size: {}\".format(n_matched, max_size))\n",
    "\n",
    "    # sort by values\n",
    "    sizes_sorted = sorted(sizes.items(), key=operator.itemgetter(1))\n",
    "    summarize_dict(sizes, topn=15, sort_=True)\n",
    "\n",
    "    print(\"> sizes: {}\".format(sizes.most_common(20)))\n",
    "    most_sample_sizes = sizes.most_common(topn)  # take(topn, sizes.items())\n",
    "    print(\"> Sample sizes | Top N={} codes:\\n{}\\n\".format(topn, most_sample_sizes))\n",
    "    least_sample_sizes = sizes.most_common()[:-topn-1:-1]\n",
    "    print(\"> Sample sizss | Last N={} codes:\\n{}\\n\".format(topn, least_sample_sizes))\n",
    "\n",
    "    # test\n",
    "    target = most_sample_sizes[0][0]\n",
    "    y = encode_labels(dfy, pos_label=target, codebook=codebook, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_tree, utils_sys, analyzer\n",
    "import collections\n",
    "from analyzer import balance_by_downsampling\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from loinc import TSet\n",
    "\n",
    "def get_sample_size(y, code_book={}):\n",
    "    if not code_book: code_book = TSet.code_book\n",
    "    counter = collections.Counter(y)\n",
    "    return (counter[codebook['neg']], counter[codebook['pos']])\n",
    "\n",
    "# data transformation\n",
    "col = 'test_result_loinc_code'\n",
    "X, y = dfX.values, dfy[col].values\n",
    "print(\"> dim(X): {}, sample(y): {}\".format(X.shape, np.random.choice(np.unique(y),20) ))\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler() # MinMaxScaler(), StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "n_fold = 5\n",
    "n_min = n_fold\n",
    "\n",
    "# to save performance data\n",
    "header = ['code', 'mean', 'std', 'n_pos']\n",
    "sdict = {h:[] for h in header}\n",
    "for code in loinc_set: \n",
    "    y_eff = analyzer.encode_labels(y, pos_label=code)\n",
    "    \n",
    "    n_neg, n_pos = get_sample_size(y_eff)\n",
    "    print(f\"> sample size | n0(+): {n_pos}, n0(-): {n_neg}\")\n",
    "    \n",
    "    if n_pos >= n_min: \n",
    "        # additional step to balance control sample size (in 1-vs-all, the 'other' class tends to be too large) \n",
    "        X_eff, y_eff = balance_by_downsampling(X, y_eff, method='multiple')\n",
    "        n_neg, n_pos = get_sample_size(y_eff)\n",
    "        print(f\"> sample size (after downsampling) | n(+): {n_pos}, n(-): {n_neg}\")\n",
    "        \n",
    "        # training + evaluation (default classifier: logistic regression)\n",
    "        scores = analyzer.eval_performance(X_eff, y_eff, model=None, cv=n_fold, random_state=53, verbose=1)\n",
    "        \n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores)\n",
    "        print(\"> average: {}, std: {}\".format(mean_score, std_score))\n",
    "    else: \n",
    "        print(\"> (positive) sample size too small, n={}\".format(n_pos))\n",
    "        mean_score = -1 \n",
    "        std_score = -1\n",
    "    sdict['code'].append(code)\n",
    "    sdict['mean'].append(mean_score)\n",
    "    sdict['std'].append(std_score)\n",
    "    sdict['n_pos'].append(n_pos)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# save performance dataframe\n",
    "df_perf = DataFrame(sdict, columns=header)\n",
    "df_perf = df_perf.sort_values(by=['mean', ]) # ascending=False\n",
    "analyzer.save_performnace(df, output_dir='result', output_file='', **kargs)\n",
    "\n",
    "cohort = 'hepatitis-c'\n",
    "output_dir = os.path.join(os.getcwd(), 'result')\n",
    "output_file = f\"performance-{cohort}-3.csv\" \n",
    "output_path = os.path.join(output_dir, output_file)\n",
    "df_perf.to_csv(output_path, sep='|', index=False, header=True)\n",
    "\n",
    "for code, score in zip(df_perf['code'], df_perf['mean']):\n",
    "    print(f\"[{code}] -> {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Memo\n",
    "---- \n",
    "1. performance plot\n",
    "\n",
    "   perplot: https://pypi.org/project/perfplot/\n",
    "\"\"\"\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from analyzer import load_performance\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(6, 20))\n",
    "sns.set_color_codes(\"pastel\")\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "# load performance data\n",
    "cohort = 'hepatitis-c'\n",
    "df_perf = load_performance(input_dir='result', cohort=cohort)\n",
    "print(\"> dim(performance matrix): {}\".format(df_perf.shape))\n",
    "\n",
    "# sort ~ performance scores \n",
    "# df_perf = df_perf.sort_values(by=['mean', ], ascending=False)\n",
    "\n",
    "header = ['code', 'mean', 'std', 'n_pos']\n",
    "codes = df_perf['code']\n",
    "n_codes = len(codes)\n",
    "scores = df_perf['mean']\n",
    "\n",
    "# some statistics\n",
    "score_high = 0.90\n",
    "score_low = 0.50\n",
    "\n",
    "codes_low_sz = df_perf.loc[df_perf['mean'] < 0]['code']\n",
    "codes_scored = df_perf.loc[df_perf['mean'] >= 0]['code']\n",
    "codes_high_score = df_perf.loc[df_perf['mean'] >= score_high]['code']\n",
    "assert n_codes == len(codes_low_sz) + len(codes_scored)\n",
    "\n",
    "print(\"1. Total number of codes: {} | n(low_sample): {}, n(scored):{}, n(high scored):{}\".format(n_codes, \n",
    "   len(codes_low_sz), len(codes_scored), len(codes_high_score)))\n",
    "r_scored = len(codes_scored)/(n_codes+0.0)\n",
    "rh = len(codes_high_score)/(n_codes+0.0)\n",
    "print(\"2. Fraction of scored codes: {}\".format(r_scored))\n",
    "print(\"3. Fraction of highly scored codes: {}\".format(rh))\n",
    "\n",
    "# Effective performance dataframe, ruling out those codes without scores (due to low sample sizes)\n",
    "df_eff = df_perf.loc[df_perf['mean'] >= 0.0]\n",
    "\n",
    "n_offset = 25\n",
    "df_topn = df_eff.sort_values(['mean', ], ascending=False).head(n_offset)\n",
    "df_botn = df_eff.sort_values(['mean', ], ascending=True).head(n_offset)\n",
    "# print(df_botn)\n",
    "\n",
    "# codes = [str(c) for c in df_botn['code'].values]\n",
    "# print('lower codes: {}'.format(codes))\n",
    "# scores = df_botn['mean'].values\n",
    "# print('scores: {}'.format(scores))\n",
    "\n",
    "# top n + bottom n\n",
    "dfe = pd.concat([df_topn, df_botn], ignore_index=True)\n",
    "dfe.sort_values(by=['mean', ], ascending=False, inplace=True)\n",
    "codes = [str(c) for c in dfe['code'].values]\n",
    "scores = dfe['mean'].values\n",
    "# print('lower(n)+higher codes(n): {}'.format(codes))\n",
    "# print('scores: {}'.format(scores))\n",
    "print(dfe)\n",
    "\n",
    "# sns.barplot(x=\"total\", y=\"abbrev\", data=crashes,\n",
    "#             label=\"Total\", color=\"b\")\n",
    "\n",
    "# --------------------\n",
    "# ax = sns.barplot(x='mean', y='code', data=df_botn)\n",
    "# print(\"-------------------------\\n\\n\")\n",
    "# print(\"> dtype: {}\".format(df_botn.dtypes))\n",
    "# print(df_botn.head(10))\n",
    "\n",
    "# dfe = dfe[['mean', 'code']]\n",
    "# dfe.plot(kind='bar')\n",
    "\n",
    "sns.barplot(x='mean', y='code', data=dfe, order=dfe['code'], # order has to be specified; even if already sorted!!!\n",
    "            label=\"LOINC\", color=\"b\", orient='h')\n",
    "\n",
    "# ax = sns.barplot(x='mean', y='code', data=df)\n",
    "\n",
    "# ax.set_xlabel('Fmax Score')\n",
    "# ax.set_ylabel('LOINC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
