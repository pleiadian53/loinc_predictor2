{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import DataFrame, Series\n",
    "import os, sys, re\n",
    "import numpy as np\n",
    "\n",
    "from decimal import Decimal\n",
    "from tabulate import tabulate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # action='once'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyzer import interpret\n",
    "\n",
    "def col_values(df, col='age', n=10):\n",
    "    df_subset = df.sample(n=n, random_state=1) # for each column, sample n values (usually n=1)\n",
    "    return df_subset[col].values\n",
    "\n",
    "def summary(df, n=1): \n",
    "    msg = \"\"\n",
    "    msg += \"> sample sizes: {}\\n\".format(df.shape[0])\n",
    "    msg += \"> n(features):  {}\\n\".format(df.shape[1])\n",
    "    # msg += \"> list of features:\\n{}\\n\".format(df.columns.values)\n",
    "    print(msg)\n",
    "\n",
    "    interpret(df, n=n, verbose=True)\n",
    "def show_dict(adict, topn=-1, by='', header=[], n_samples=-1, ascending=False, print_=False): \n",
    "    # print(adict)\n",
    "    \n",
    "    # convert to two-column dataframe format \n",
    "    if not header: \n",
    "        header = ['key', 'value']\n",
    "    else: \n",
    "        assert len(header) == 2\n",
    "    D = {h:[] for h in header}\n",
    "    for k, v in adict.items(): \n",
    "        D[header[0]].append(k)\n",
    "        D[header[1]].append(v)\n",
    "    \n",
    "    df = DataFrame(D, columns=header)\n",
    "    msg = ''\n",
    "    if topn > 0: \n",
    "        assert by in df.columns\n",
    "        df = df.sort_values([by, ], ascending=ascending)\n",
    "        msg = tabulate(df[:topn], headers='keys', tablefmt='psql')\n",
    "    else: \n",
    "        if n_samples < 0: \n",
    "            msg = tabulate(df, headers='keys', tablefmt='psql')\n",
    "        else: \n",
    "            n = min(df.shape[0], n_samples)\n",
    "            msg = tabulate(df.sample(n=n), headers='keys', tablefmt='psql')\n",
    "    if print_: print(msg)\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine and Retrieve Patient Cohort(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Find rows whose column match a substring \n",
    "   https://davidhamann.de/2017/06/26/pandas-select-elements-by-string/\n",
    "   \n",
    "   https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html\n",
    "\n",
    "\"\"\"\n",
    "import json \n",
    "from cohort_search import gen_code_set, gen_query_str\n",
    "\n",
    "# use module cohort_search to generate the desired query strings \n",
    "# run CohortRetrieval on Databricks (https://dbc-25924283-13f6.cloud.databricks.com/#notebook/1971793/command/1973735)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Base/Positive Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(load_data) Loaded dataframe (dim=(71224, 127)) from:\n",
      "/Users/barnett/Documents/work/loinc_predictor/data/andromeda-pond-hepatitis-c.csv\n",
      "\n",
      "(resolve_duplicate) n0: 71224 =?= n1: 71224\n",
      "(resolve_duplicate) Found 596 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "> dim(ts0): (69710, 128)\n",
      "> N(loinc_set): 733 | example codes (source):\n",
      "['51953', '755082', '885178', '98426', '7310', '63313', '483453', '425959', '178640', '30741', '139956', '204552', '161901', '30130', '154120', '204966', '191395', '133629', '111567', '349993', '351684', '19869', '332551', '505511', '7518', '7047', '28902', '20008', '237610', '58214']\n",
      "\n",
      "> dim(performance matrix): (733, 4)\n",
      "> Set the baseline class sample size: Nmax: 12033 (Nmax0: 4079, median: 7.0)\n",
      "> top 10 sample sizes:\n",
      "+----+---------+---------+\n",
      "|    | code    |   n_pos |\n",
      "|----+---------+---------|\n",
      "|  0 | unknown |   12033 |\n",
      "|  1 | 67686   |    5720 |\n",
      "|  2 | 19752   |    4454 |\n",
      "|  3 | 17426   |    4445 |\n",
      "|  4 | 17517   |    4399 |\n",
      "|  5 | 21600   |    4207 |\n",
      "|  6 | 178616  |    3870 |\n",
      "|  7 | 7773    |    3698 |\n",
      "|  8 | 7187    |    3688 |\n",
      "|  9 | 486431  |    3671 |\n",
      "+----+---------+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nConclusion \\n----------\\n\\nCohort: hepatitis-c\\n\\n1. max sample size with known code: 67686 => 57202\\n2. loinc_set: target loinc codes\\n   size(loinc_set): 733\\n3. ts0: dim=(71224, 127)\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from analyzer import load_data, save_data, load_performance, stratify\n",
    "# from transformer import canonicalize  # ... obsolete\n",
    "from transformer import resolve_duplicate\n",
    "import loinc as lc\n",
    "# from loinc import canonicalize\n",
    "\n",
    "######################################\n",
    "# params\n",
    "cohort = domain = 'hepatitis-c'\n",
    "token_default = 'unknown'\n",
    "col_target = 'test_result_loinc_code'\n",
    "######################################\n",
    "\n",
    "# load source data\n",
    "ts0 = load_data(input_file='andromeda-pond-hepatitis-c.csv', warn_bad_lines=False)\n",
    "# ts0 = ts0.drop_duplicates(keep='last')  # drop duplicates \n",
    "ts0 = resolve_duplicate(ts0)  # add_count/True: adding extra column: 'count'\n",
    "ts0 = lc.canonicalize(ts0, col_target=col_target, token_missing=token_default)\n",
    "\n",
    "print(\"> dim(ts0): {}\".format(ts0.shape))  \n",
    "loinc_set = codes0 = ts0[col_target].unique()\n",
    "codes0_subset = np.random.choice(codes0, 30)\n",
    "print(\"> N(loinc_set): {} | example codes (source):\\n{}\\n\".format(len(loinc_set), list(codes0_subset)))\n",
    "\n",
    "# stratify the data by class labels (e.g. LOINC codes)\n",
    "ds = stratify(ts0, col=col_target) # code|mean|std|n_pos\n",
    "Nmax0 = ds[0][1]  \n",
    "# ... here we have not added extra control data yet (i.e. patients without the target disease such hepatitis C)\n",
    "\n",
    "# compare to the previously generated performance dataframe\n",
    "df_perf = load_performance(input_dir='result', cohort=cohort)\n",
    "df_perf = df_perf.sort_values(by=['n_pos', ], ascending=False)\n",
    "Nmax = np.max(df_perf['n_pos'].values)\n",
    "Nm = np.median(df_perf['n_pos'].values)\n",
    "\n",
    "ss_dict = dict(zip(df_perf['code'].values, df_perf['n_pos'].values))\n",
    "print(\"> Set the baseline class sample size: Nmax: {} (Nmax0: {}, median: {})\".format(Nmax, Nmax0, Nm))\n",
    "\n",
    "topn = 10\n",
    "print(\"> top {} sample sizes:\\n{}\\n\".format(topn, show_dict(ss_dict, topn=topn, \n",
    "        by='n_pos', header=['code', 'n_pos'])))\n",
    "\n",
    "######################################\n",
    "\"\"\"\n",
    "Conclusion \n",
    "----------\n",
    "\n",
    "Cohort: hepatitis-c\n",
    "\n",
    "1. max sample size with known code: 67686 => 57202\n",
    "2. loinc_set: target loinc codes\n",
    "   size(loinc_set): 733\n",
    "3. ts0: dim=(71224, 127)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Control Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(load_data) Loaded dataframe (dim=(2891340, 127)) from:\n",
      "/Users/barnett/Documents/work/loinc_predictor/data/andromeda_pond-10p.csv\n",
      "\n",
      "(resolve_duplicate) n0: 2891340 =?= n1: 2891340\n",
      "(resolve_duplicate) Found 4442 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "> dim(ts_ctrl): (2639054, 128)\n",
      "(save_data) Saved dataframe (dim=(2639054, 128)) to:\n",
      "/Users/barnett/Documents/work/loinc_predictor/data/andromeda-pond-hepatitis-c-ctrl.csv\n",
      "\n",
      "> Adding control data | N: 69710 -> 139420\n"
     ]
    }
   ],
   "source": [
    "# patients not in given domain/disease\n",
    "from cohort_search import filter_by_diagnosis\n",
    "from analyzer import save_data\n",
    "from transformer import resolve_duplicate\n",
    "\n",
    "######################################\n",
    "# params\n",
    "tFilter = False\n",
    "tSave = True\n",
    "tAddCtrl = True\n",
    "output_dir = 'data'\n",
    "######################################\n",
    "\n",
    "N0 = ts0.shape[0]\n",
    "\n",
    "# load source data\n",
    "ts_ctrl = load_data(input_file='andromeda_pond-10p.csv', warn_bad_lines=False)\n",
    "# ts_ctrl = ts_ctrl.drop_duplicates(keep='last')  # drop duplicates\n",
    "ts_ctrl = resolve_duplicate(ts_ctrl)\n",
    "ts_ctrl = lc.canonicalize(ts_ctrl, col_target=col_target, token_missing=token_default, target_labels=loinc_set)\n",
    "print(\"> dim(ts_ctrl): {}\".format(ts_ctrl.shape))  \n",
    "\n",
    "if tFilter: \n",
    "    ts_ctrl = filter_by_diagnosis(ts_ctrl, condition='hepatitis c')\n",
    "    nctrl = ts_ctrl.shape[0]\n",
    "    print(\"> sample size | orig: {}, filtered(control): {}\".format(n0, nctrl))\n",
    "\n",
    "# summary(df_ctrl, n=1)\n",
    "# df_ctrl.info()   \n",
    "\n",
    "# save \n",
    "if tSave: \n",
    "    output_file = f\"andromeda-pond-{cohort}-ctrl.csv\" \n",
    "    save_data(ts_ctrl,  output_file=output_file, sep=',')\n",
    "    \n",
    "# mix-in \n",
    "if tAddCtrl: \n",
    "    Nctrl = ts_ctrl.shape[0]\n",
    "    assert Nctrl > N0, f\"Control data is too small | n({cohort})={N0} > n(ctrl)={Nctrl}\"\n",
    "    ts_ctrl = ts_ctrl.sample(n=N0, replace=False)\n",
    "    \n",
    "    ts0 = pd.concat([ts0, ts_ctrl], ignore_index=True)\n",
    "    \n",
    "assert np.sum(ts0[col_target].isnull()) == 0\n",
    "print(\"> Adding control data | N: {} -> {}\".format(N0, ts0.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Feature Set \n",
    "\n",
    "Note: Subsetting columns could potentially reduce the size of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Memo\n",
    "----\n",
    "1. medivo_test_result_type is a function of the following attributes: \n",
    "      \"meta_sender_name\",\n",
    "      \"receiving_organization_id\",\n",
    "      \"test_order_code\",\n",
    "      \"test_order_name\",\n",
    "      \"test_result_code\",\n",
    "      \"test_result_name\",\n",
    "      \"test_result_loinc_code\",\n",
    "      \"test_result_units_of_measure\"\n",
    "      \n",
    "\"\"\"\n",
    "from transformer import to_age\n",
    "from analyzer import sample_col_values\n",
    "from loinc import FeatureSet\n",
    "\n",
    "cat_cols = ['patient_gender', \n",
    "            'patient_state',  # n_uniq=199\n",
    "            'patient_bill_type',  # n_uniq=31\n",
    "            'fasting',   # n_uniq=5\n",
    "            \n",
    "            'performing_organization_id', # n_uniq=151, m=40%+, NOT part of medivo_test_result_type\n",
    "            \n",
    "            'receiving_organization_id', # n_uniq=43, m=50%+, part of medivo_test_result_type\n",
    "            # 'receiving_organization_name', \n",
    "            \n",
    "            # 'receiving_organization_state', \n",
    "            # 'receiving_organization_zip_code', \n",
    "            \n",
    "            # 'ordering_practice_lab_account_name',  # high card\n",
    "            # 'ordering_practice_lab_account_number', # high card\n",
    "            \n",
    "            # 'ordering_practice_city', # high card \n",
    "            # 'ordering_practice_state', # high card 124? \n",
    "            \n",
    "            # 'ordering_practice_zip_code', # high card,  n_uniq=79392\n",
    "            # 'ordering_provider_alternate_id_type',   # n_uniq=32\n",
    "            \n",
    "            # 'ordering_provider_alternate_id', # n_uniq=132768\n",
    "            \n",
    "            # ---------------------------------\n",
    "            \n",
    "            'test_result_status', # n_uniq=144\n",
    "            # 'test_turnaround_time', # n_uniq=417, high missing\n",
    "            \n",
    "            'test_order_code',  # n_uniq=27668\n",
    "            'test_order_name',  # n_uniq=20039\n",
    "            \n",
    "            'test_result_code', # n_uniq=23731 (2771052/2891340)\n",
    "            'test_result_name',  # n_uniq=15581    # <<<< \n",
    "            \n",
    "            'test_result_value',  # n_uniq=35441    # <<<< \n",
    "            'test_result_range',   # n_uniq=151, mostly missing   # <<<< \n",
    "            \n",
    "            'test_result_abnormal_flag',  # n_uniq=524, high missing\n",
    "            \n",
    "            'test_result_reference_range',  # n_uniq=5735, moderate missing\n",
    "            \n",
    "            'test_result_units_of_measure',  # n_uniq=669, m=40%+\n",
    "            \n",
    "            # 'test_result_comment_source', # mostly missing\n",
    "            \n",
    "            'test_result_comments',  # mostly missing > 80%   # <<<< \n",
    "            \n",
    "            # 'test_priority', \n",
    "            # 'test_specimen_collection_volume',\n",
    "            \n",
    "            # 'test_specimen_type',  # mostly missing\n",
    "            \n",
    "            # 'test_specimen_source', # n_uniq=15971\n",
    "            # 'test_relevant_clinical_information', # n_uniq=26/\n",
    "            \n",
    "            'test_cpt_code',    # n_uniq=655\n",
    "            \n",
    "            # 'parent_test_order_code', # n_uniq=5088\n",
    "            # 'parent_test_order_name', # high missing\n",
    "            \n",
    "            # --- datetime ---\n",
    "            # 'test_specimen_draw_datetime',  # e.g. '2019-08-07T14:47:00.000Z'\n",
    "            # 'test_specimen_receipt_datetime', #  e.g. '2016-10-06T10:54:00.000Z\n",
    "            \n",
    "            # 'test_specimen_analysis_datetime', # high missin\n",
    "            # 'test_observation_datetime', \n",
    "            \n",
    "            # 'test_observation_reported_datetime', \n",
    "            \n",
    "            'panel_order_code',  # n_uniq=18018\n",
    "            'panel_order_name',  # n_uniq=11663\n",
    "            \n",
    "            # 'parent_panel_order_code', # high missing\n",
    "            # 'parent_panel_order_name', # high missing\n",
    "            \n",
    "            # 'datetime_of_processing',  # no year e.g. 'Jun 29 14:44:25'\n",
    "            \n",
    "            # 'meta_ingestion_datetime',\n",
    "            \n",
    "            'meta_sender_name',  #  n_uniq=7, m=0 # <<< \n",
    "            'medivo_test_result_type',  # n_uniq=3493, <<<<\n",
    "        \n",
    "            ]\n",
    "\n",
    "cont_cols = ['age',   # patient_gender -> age  # <<< \n",
    "     ]  \n",
    "\n",
    "target_cols = ['test_result_loinc_code', ]\n",
    "\n",
    "derived_cols = ['count',  # due to resolve_duplicate()\n",
    "               ]\n",
    "\n",
    "# cardinality < 100\n",
    "low_card_cols = ['patient_gender', 'fasting', 'meta_sender_name' ]\n",
    "high_card_cols = list(set(cat_cols)-set(low_card_cols))\n",
    "\n",
    "representative_cols = [\"meta_sender_name\",\n",
    "      # \"receiving_organization_id\",\n",
    "      # \"test_order_code\",\n",
    "      \"test_order_name\",\n",
    "      # \"test_result_code\",\n",
    "      \"test_result_name\",\n",
    "      \"test_result_loinc_code\",\n",
    "      \"test_result_units_of_measure\"]\n",
    "\n",
    "target_columns = cat_cols + cont_cols + target_cols\n",
    "\n",
    "# feature transformation\n",
    "#####################################################\n",
    "# to_age(ts0)\n",
    "# values = sample_col_values(ts0, col='age', n=10)\n",
    "# print(\"> age: {}\".format(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Classes \n",
    "\n",
    "note: balance classes from external dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(balance_classes) data size distribution:\n",
      "[('67686', 5872), ('17426', 4647), ('17517', 4602), ('19752', 4562), ('21600', 4379), ('unknown', 4267), ('178616', 4001), ('7773', 3938), ('7187', 3917), ('486431', 3861), ('30973', 3851), ('19208', 3726), ('66902', 3405), ('28233', 3142), ('7310', 3104), ('7112', 2848), ('7138', 2827), ('110114', 2566), ('7708', 2503), ('7518', 2471), ('45443', 2452), ('20859', 2373), ('25718', 2372), ('20933', 2323), ('134577', 2262)]\n",
      "\n",
      "(balance_classes) We have n=731 with low sample size (< 5872)\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 840 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[0] Processing chunk #1 | n(ts): 139420, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=476 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 476 common codes from the df_extern:\n",
      "['30130', '823799', '384834', '52472', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '63313', '7328', '62372', '557520', '31427', '28233']\n",
      "\n",
      "(balance_data_incr) Added n=554 cases to code=128512\n",
      "(balance_data_incr) Added n=1 cases to code=148049\n",
      "(balance_data_incr) Added n=747 cases to code=17590\n",
      "(balance_data_incr) Added n=2146 cases to code=19208\n",
      "(balance_data_incr) Added n=20 cases to code=20644\n",
      "(balance_data_incr) Added n=4989 cases to code=23457\n",
      "(balance_data_incr) Added n=3500 cases to code=25718\n",
      "(balance_data_incr) Added n=560 cases to code=28746\n",
      "(balance_data_incr) Added n=21 cases to code=30403\n",
      "(balance_data_incr) Added n=207 cases to code=326249\n",
      "(balance_data_incr) Added n=1 cases to code=381772\n",
      "(balance_data_incr) Added n=3792 cases to code=45377\n",
      "(balance_data_incr) Added n=377 cases to code=50484\n",
      "(balance_data_incr) Added n=272 cases to code=542183\n",
      "(balance_data_incr) Added n=21 cases to code=60822\n",
      "(balance_data_incr) Added n=19 cases to code=7021\n",
      "(balance_data_incr) Added n=166 cases to code=7534\n",
      "(balance_data_incr) Added n=154 cases to code=81224\n",
      "(balance_data_incr) Added n=10 cases to code=98426\n",
      "(balance_data_incr) Added n=475 cases in total | n_miss:257 ... #\n",
      "... missed (n=257):\n",
      "['143149', '451765', '115659', '744441', '110064', '79095', '594192', '487967', '303842', '81372', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741']\n",
      "\n",
      "... hit (n=475):\n",
      "['30130', '823799', '384834', '52472', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '33902', '63313', '62372', '7328', '557520', '31427', '28233']\n",
      "\n",
      "(balance_data) N_extra: 263843\n",
      "[0] size: 139420 -> 403263\n",
      "[0] size(codes) < 5872 (n=697): \n",
      "[('19893', 5854), ('28852', 5401), ('481598', 4304), ('unknown', 4267), ('28571', 4077), ('45377', 4063), ('254284', 4042), ('139550', 4007), ('771477', 3959), ('63016', 3631), ('110114', 3253), ('19687', 3104), ('93187', 2882), ('19885', 2839), ('226381', 2803), ('29868', 2328), ('22764', 2325), ('24984', 2324), ('19711', 2192), ('other', 2182)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 817 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[1] Processing chunk #2 | n(ts): 403263, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=474 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 474 common codes from the df_extern:\n",
      "['823799', '30130', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '110908', '63313', '7328', '62372', '557520']\n",
      "\n",
      "(balance_data_incr) Added n=5 cases to code=122861\n",
      "(balance_data_incr) Added n=6 cases to code=143149\n",
      "(balance_data_incr) Added n=35 cases to code=17442\n",
      "(balance_data_incr) Added n=1077 cases to code=191239\n",
      "(balance_data_incr) Added n=5 cases to code=205211\n",
      "(balance_data_incr) Added n=9 cases to code=23366\n",
      "(balance_data_incr) Added n=235 cases to code=257006\n",
      "(balance_data_incr) Added n=643 cases to code=28746\n",
      "(balance_data_incr) Added n=26 cases to code=304337\n",
      "(balance_data_incr) Added n=433 cases to code=327312\n",
      "(balance_data_incr) Added n=325 cases to code=369165\n",
      "(balance_data_incr) Added n=19 cases to code=509562\n",
      "(balance_data_incr) Added n=855 cases to code=568881\n",
      "(balance_data_incr) Added n=561 cases to code=622910\n",
      "(balance_data_incr) Added n=208 cases to code=7120\n",
      "(balance_data_incr) Added n=2 cases to code=772020\n",
      "(balance_data_incr) Added n=10 cases to code=823773\n",
      "(balance_data_incr) Added n=473 cases in total | n_miss:259 ... #\n",
      "... missed (n=259):\n",
      "['451765', '115659', '744441', '487967', '426171', '303842', '81372', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355', '320184', '461285']\n",
      "\n",
      "... hit (n=473):\n",
      "['30130', '823799', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '110908', '33902', '63313', '62372', '7328', '557520']\n",
      "\n",
      "(balance_data) N_extra: 126610\n",
      "[1] size: 403263 -> 529873\n",
      "[1] size(codes) < 5872 (n=688): \n",
      "[('226381', 5804), ('93187', 5644), ('19687', 5619), ('19885', 5242), ('29868', 4668), ('30841', 4417), ('22764', 4386), ('24984', 4319), ('unknown', 4267), ('19711', 4179), ('557520', 4027), ('110114', 3995), ('312082', 3965), ('191395', 3889), ('82511', 3872), ('22368', 3572), ('19901', 3547), ('25023', 3375), ('23242', 3350), ('25007', 3266)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 819 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[2] Processing chunk #3 | n(ts): 529873, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=480 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 480 common codes from the df_extern:\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '110908', '63313', '7328', '62372', '557520', '31427']\n",
      "\n",
      "(balance_data_incr) Added n=108 cases to code=122358\n",
      "(balance_data_incr) Added n=5 cases to code=143081\n",
      "(balance_data_incr) Added n=1090 cases to code=191239\n",
      "(balance_data_incr) Added n=11 cases to code=205211\n",
      "(balance_data_incr) Added n=122 cases to code=22848\n",
      "(balance_data_incr) Added n=15 cases to code=25395\n",
      "(balance_data_incr) Added n=584 cases to code=28688\n",
      "(balance_data_incr) Added n=584 cases to code=303768\n",
      "(balance_data_incr) Added n=56 cases to code=322156\n",
      "(balance_data_incr) Added n=21 cases to code=354621\n",
      "(balance_data_incr) Added n=267 cases to code=44982\n",
      "(balance_data_incr) Added n=104 cases to code=495416\n",
      "(balance_data_incr) Added n=80 cases to code=544346\n",
      "(balance_data_incr) Added n=24 cases to code=60822\n",
      "(balance_data_incr) Added n=18 cases to code=7021\n",
      "(balance_data_incr) Added n=487 cases to code=7641\n",
      "(balance_data_incr) Added n=502 cases to code=81232\n",
      "(balance_data_incr) Added n=1 cases to code=96644\n",
      "(balance_data_incr) Added n=479 cases in total | n_miss:253 ... #\n",
      "... missed (n=253):\n",
      "['451765', '384834', '744441', '487967', '303842', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355', '320184', '461285', '111252', '7682']\n",
      "\n",
      "... hit (n=479):\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '110908', '33902', '63313', '62372', '7328', '557520', '31427']\n",
      "\n",
      "(balance_data) N_extra: 99691\n",
      "[2] size: 529873 -> 629564\n",
      "[2] size(codes) < 5872 (n=676): \n",
      "[('82511', 5723), ('22368', 5383), ('19901', 5358), ('25023', 5128), ('25007', 5091), ('25015', 4787), ('23242', 4757), ('110114', 4744), ('264994', 4655), ('27771', 4337), ('226357', 4269), ('unknown', 4267), ('21576', 4242), ('29918', 4214), ('7856', 4101), ('422543', 4049), ('27318', 3885), ('7369', 3562), ('293001', 3492), ('29512', 3426)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 804 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[3] Processing chunk #4 | n(ts): 629564, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=482 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 482 common codes from the df_extern:\n",
      "['30130', '823799', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '63313', '7328', '62372', '557520', '31427']\n",
      "\n",
      "(balance_data_incr) Added n=9 cases to code=122861\n",
      "(balance_data_incr) Added n=1 cases to code=143149\n",
      "(balance_data_incr) Added n=112 cases to code=205070\n",
      "(balance_data_incr) Added n=5 cases to code=23366\n",
      "(balance_data_incr) Added n=225 cases to code=257006\n",
      "(balance_data_incr) Added n=586 cases to code=28746\n",
      "(balance_data_incr) Added n=20 cases to code=303925\n",
      "(balance_data_incr) Added n=5 cases to code=325852\n",
      "(balance_data_incr) Added n=328 cases to code=369165\n",
      "(balance_data_incr) Added n=49 cases to code=453530\n",
      "(balance_data_incr) Added n=23 cases to code=495499\n",
      "(balance_data_incr) Added n=91 cases to code=544346\n",
      "(balance_data_incr) Added n=30 cases to code=60756\n",
      "(balance_data_incr) Added n=16 cases to code=7021\n",
      "(balance_data_incr) Added n=56 cases to code=81174\n",
      "(balance_data_incr) Added n=6 cases to code=96107\n",
      "(balance_data_incr) Added n=481 cases in total | n_miss:251 ... #\n",
      "... missed (n=251):\n",
      "['451765', '744441', '79095', '487967', '303842', '81372', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355', '320184', '461285', '111252']\n",
      "\n",
      "... hit (n=481):\n",
      "['30130', '823799', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '33902', '63313', '62372', '7328', '557520', '31427']\n",
      "\n",
      "(balance_data) N_extra: 77628\n",
      "[3] size: 629564 -> 707192\n",
      "[3] size(codes) < 5872 (n=668): \n",
      "[('226357', 5774), ('27771', 5683), ('7856', 5595), ('29918', 5543), ('110114', 5516), ('21576', 5470), ('422543', 5299), ('27318', 5193), ('293001', 4788), ('28886', 4472), ('29512', 4463), ('20750', 4446), ('191239', 4440), ('28621', 4393), ('28902', 4379), ('51961', 4359), ('7369', 4301), ('unknown', 4267), ('110544', 4151), ('20289', 4082)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 814 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[4] Processing chunk #5 | n(ts): 707192, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=481 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 481 common codes from the df_extern:\n",
      "['30130', '823799', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '63313', '7328', '62372', '557520', '31427']\n",
      "\n",
      "(balance_data_incr) Added n=357 cases to code=128413\n",
      "(balance_data_incr) Added n=2 cases to code=143149\n",
      "(balance_data_incr) Added n=1144 cases to code=191239\n",
      "(balance_data_incr) Added n=19 cases to code=204966\n",
      "(balance_data_incr) Added n=961 cases to code=25320\n",
      "(balance_data_incr) Added n=614 cases to code=28654\n",
      "(balance_data_incr) Added n=79 cases to code=30346\n",
      "(balance_data_incr) Added n=37 cases to code=31815\n",
      "(balance_data_incr) Added n=3 cases to code=35436\n",
      "(balance_data_incr) Added n=90 cases to code=437277\n",
      "(balance_data_incr) Added n=12 cases to code=490243\n",
      "(balance_data_incr) Added n=28 cases to code=539627\n",
      "(balance_data_incr) Added n=1 cases to code=59469\n",
      "(balance_data_incr) Added n=36 cases to code=68338\n",
      "(balance_data_incr) Added n=15 cases to code=7492\n",
      "(balance_data_incr) Added n=29 cases to code=81125\n",
      "(balance_data_incr) Added n=2 cases to code=96610\n",
      "(balance_data_incr) Added n=480 cases in total | n_miss:252 ... #\n",
      "... missed (n=252):\n",
      "['451765', '115659', '744441', '79095', '487967', '303842', '81372', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355', '320184', '461285']\n",
      "\n",
      "... hit (n=480):\n",
      "['30130', '823799', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '33902', '63313', '62372', '7328', '557520', '31427']\n",
      "\n",
      "(balance_data) N_extra: 62997\n",
      "[4] size: 707192 -> 770189\n",
      "[4] size(codes) < 5872 (n=659): \n",
      "[('191239', 5584), ('28886', 5541), ('28621', 5533), ('28902', 5477), ('51961', 5473), ('20750', 5416), ('29512', 5404), ('110544', 5091), ('20289', 5042), ('7369', 4981), ('108340', 4796), ('93179', 4742), ('17590', 4696), ('25320', 4671), ('568881', 4418), ('24653', 4385), ('381806', 4337), ('unknown', 4267), ('305227', 4175), ('115725', 4023)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 825 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[5] Processing chunk #6 | n(ts): 770189, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=479 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 479 common codes from the df_extern:\n",
      "['823799', '30130', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '33902', '110908', '63313', '7328', '62372', '557520']\n",
      "\n",
      "(balance_data_incr) Added n=13 cases to code=122861\n",
      "(balance_data_incr) Added n=7 cases to code=143081\n",
      "(balance_data_incr) Added n=27 cases to code=17442\n",
      "(balance_data_incr) Added n=288 cases to code=191239\n",
      "(balance_data_incr) Added n=23 cases to code=204966\n",
      "(balance_data_incr) Added n=98 cases to code=22848\n",
      "(balance_data_incr) Added n=21 cases to code=25395\n",
      "(balance_data_incr) Added n=568 cases to code=28654\n",
      "(balance_data_incr) Added n=72 cases to code=30346\n",
      "(balance_data_incr) Added n=62 cases to code=322156\n",
      "(balance_data_incr) Added n=156 cases to code=355594\n",
      "(balance_data_incr) Added n=84 cases to code=437277\n",
      "(balance_data_incr) Added n=9 cases to code=490243\n",
      "(balance_data_incr) Added n=4 cases to code=53728\n",
      "(balance_data_incr) Added n=628 cases to code=59055\n",
      "(balance_data_incr) Added n=4 cases to code=67421\n",
      "(balance_data_incr) Added n=22 cases to code=7492\n",
      "(balance_data_incr) Added n=32 cases to code=81125\n",
      "(balance_data_incr) Added n=27 cases to code=97287\n",
      "(balance_data_incr) Added n=478 cases in total | n_miss:254 ... #\n",
      "... missed (n=254):\n",
      "['451765', '115659', '744441', '79095', '487967', '303842', '81372', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355', '320184', '461285']\n",
      "\n",
      "... hit (n=478):\n",
      "['30130', '823799', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '110908', '33902', '63313', '62372', '7328', '557520']\n",
      "\n",
      "(balance_data) N_extra: 55167\n",
      "[5] size: 770189 -> 825356\n",
      "[5] size(codes) < 5872 (n=650): \n",
      "[('25320', 5751), ('93179', 5672), ('7369', 5666), ('17590', 5629), ('108340', 5628), ('24653', 5326), ('568881', 5159), ('381806', 4972), ('305227', 4933), ('7880', 4808), ('115725', 4790), ('7872', 4768), ('20396', 4635), ('7864', 4617), ('24588', 4458), ('unknown', 4267), ('7047', 4178), ('7427', 4144), ('7062', 4126), ('59055', 3921)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 808 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[6] Processing chunk #7 | n(ts): 825356, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=475 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 475 common codes from the df_extern:\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '110908', '63313', '7328', '62372', '557520', '31427']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(balance_data_incr) Added n=8 cases to code=122861\n",
      "(balance_data_incr) Added n=1 cases to code=143149\n",
      "(balance_data_incr) Added n=28 cases to code=17442\n",
      "(balance_data_incr) Added n=330 cases to code=206243\n",
      "(balance_data_incr) Added n=183 cases to code=237610\n",
      "(balance_data_incr) Added n=20 cases to code=264507\n",
      "(balance_data_incr) Added n=27 cases to code=304337\n",
      "(balance_data_incr) Added n=442 cases to code=327312\n",
      "(balance_data_incr) Added n=4 cases to code=381772\n",
      "(balance_data_incr) Added n=49 cases to code=45765\n",
      "(balance_data_incr) Added n=5 cases to code=51268\n",
      "(balance_data_incr) Added n=284 cases to code=57703\n",
      "(balance_data_incr) Added n=22 cases to code=62372\n",
      "(balance_data_incr) Added n=257 cases to code=7146\n",
      "(balance_data_incr) Added n=1 cases to code=772020\n",
      "(balance_data_incr) Added n=1 cases to code=82206\n",
      "(balance_data_incr) Added n=474 cases in total | n_miss:258 ... #\n",
      "... missed (n=258):\n",
      "['451765', '115659', '384834', '110064', '744441', '424838', '487967', '426171', '303842', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355']\n",
      "\n",
      "... hit (n=474):\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '110908', '33902', '63313', '62372', '7328', '557520', '31427']\n",
      "\n",
      "(balance_data) N_extra: 47394\n",
      "[6] size: 825356 -> 872750\n",
      "[6] size(codes) < 5872 (n=643): \n",
      "[('305227', 5703), ('7880', 5662), ('381806', 5646), ('7872', 5602), ('115725', 5579), ('7864', 5476), ('20396', 5321), ('24588', 5216), ('7427', 4893), ('7047', 4886), ('7062', 4825), ('59055', 4656), ('unknown', 4267), ('28746', 4261), ('28654', 4198), ('622928', 4195), ('75007', 4176), ('182626', 4104), ('28688', 4069), ('128512', 4069)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 838 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[7] Processing chunk #8 | n(ts): 872750, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=474 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 474 common codes from the df_extern:\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '110908', '63313', '7328', '62372', '557520', '31427']\n",
      "\n",
      "(balance_data_incr) Added n=8 cases to code=122861\n",
      "(balance_data_incr) Added n=1 cases to code=143164\n",
      "(balance_data_incr) Added n=17 cases to code=20644\n",
      "(balance_data_incr) Added n=31 cases to code=304337\n",
      "(balance_data_incr) Added n=43 cases to code=327338\n",
      "(balance_data_incr) Added n=2 cases to code=381772\n",
      "(balance_data_incr) Added n=17 cases to code=509562\n",
      "(balance_data_incr) Added n=14 cases to code=61747\n",
      "(balance_data_incr) Added n=235 cases to code=7120\n",
      "(balance_data_incr) Added n=12 cases to code=823765\n",
      "(balance_data_incr) Added n=473 cases in total | n_miss:259 ... #\n",
      "... missed (n=259):\n",
      "['451765', '115659', '384834', '110064', '744441', '79095', '487967', '303842', '81372', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355']\n",
      "\n",
      "... hit (n=473):\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '110908', '33902', '63313', '62372', '7328', '557520', '31427']\n",
      "\n",
      "(balance_data) N_extra: 39765\n",
      "[7] size: 872750 -> 912515\n",
      "[7] size(codes) < 5872 (n=636): \n",
      "[('24588', 5821), ('7047', 5569), ('7427', 5540), ('7062', 5461), ('59055', 5319), ('28746', 4847), ('622928', 4802), ('28654', 4755), ('75007', 4675), ('28688', 4671), ('128512', 4650), ('182626', 4628), ('303768', 4490), ('unknown', 4267), ('178566', 4229), ('622910', 4113), ('7328', 4069), ('339440', 4031), ('16493', 3876), ('24729', 3867)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 820 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[8] Processing chunk #9 | n(ts): 912515, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=481 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 481 common codes from the df_extern:\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '110908', '63313', '7328', '62372', '557520', '31427']\n",
      "\n",
      "(balance_data_incr) Added n=7 cases to code=115808\n",
      "(balance_data_incr) Added n=15 cases to code=142778\n",
      "(balance_data_incr) Added n=108 cases to code=172841\n",
      "(balance_data_incr) Added n=176 cases to code=18846\n",
      "(balance_data_incr) Added n=634 cases to code=28654\n",
      "(balance_data_incr) Added n=20 cases to code=303610\n",
      "(balance_data_incr) Added n=28 cases to code=31815\n",
      "(balance_data_incr) Added n=62 cases to code=354621\n",
      "(balance_data_incr) Added n=226 cases to code=44859\n",
      "(balance_data_incr) Added n=15 cases to code=495036\n",
      "(balance_data_incr) Added n=7 cases to code=53728\n",
      "(balance_data_incr) Added n=2 cases to code=594192\n",
      "(balance_data_incr) Added n=10 cases to code=68965\n",
      "(balance_data_incr) Added n=174 cases to code=7534\n",
      "(balance_data_incr) Added n=52 cases to code=81166\n",
      "(balance_data_incr) Added n=4 cases to code=96107\n",
      "(balance_data_incr) Added n=480 cases in total | n_miss:252 ... #\n",
      "... missed (n=252):\n",
      "['451765', '384834', '744441', '487967', '303842', '81372', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355', '320184', '461285', '67702']\n",
      "\n",
      "... hit (n=480):\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '110908', '33902', '63313', '62372', '7328', '557520', '31427']\n",
      "\n",
      "(balance_data) N_extra: 36696\n",
      "[8] size: 912515 -> 949211\n",
      "[8] size(codes) < 5872 (n=631): \n",
      "[('28746', 5460), ('28654', 5389), ('622928', 5331), ('28688', 5276), ('128512', 5275), ('75007', 5226), ('182626', 5161), ('303768', 5078), ('178566', 4647), ('622910', 4619), ('339440', 4569), ('7328', 4567), ('16493', 4389), ('24729', 4341), ('81232', 4329), ('21626', 4290), ('unknown', 4267), ('7641', 4186), ('191130', 4094), ('244673', 4089)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 840 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[9] Processing chunk #10 | n(ts): 949211, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=478 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 478 common codes from the df_extern:\n",
      "['30130', '823799', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '110908', '63313', '7328', '62372', '557520']\n",
      "\n",
      "(balance_data_incr) Added n=87 cases to code=122358\n",
      "(balance_data_incr) Added n=4 cases to code=143081\n",
      "(balance_data_incr) Added n=35 cases to code=17442\n",
      "(balance_data_incr) Added n=4 cases to code=205211\n",
      "(balance_data_incr) Added n=167 cases to code=28712\n",
      "(balance_data_incr) Added n=573 cases to code=303768\n",
      "(balance_data_incr) Added n=242 cases to code=322867\n",
      "(balance_data_incr) Added n=5 cases to code=36830\n",
      "(balance_data_incr) Added n=46 cases to code=453530\n",
      "(balance_data_incr) Added n=26 cases to code=495499\n",
      "(balance_data_incr) Added n=82 cases to code=54031\n",
      "(balance_data_incr) Added n=30 cases to code=60756\n",
      "(balance_data_incr) Added n=443 cases to code=7641\n",
      "(balance_data_incr) Added n=120 cases to code=81224\n",
      "(balance_data_incr) Added n=477 cases in total | n_miss:255 ... #\n",
      "... missed (n=255):\n",
      "['451765', '744441', '79095', '487967', '303842', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355', '320184', '461285', '67702', '111252']\n",
      "\n",
      "... hit (n=477):\n",
      "['30130', '823799', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '110908', '33902', '63313', '62372', '7328', '557520']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(balance_data) N_extra: 34558\n",
      "[9] size: 949211 -> 983769\n",
      "[9] size(codes) < 5872 (n=626): \n",
      "[('28688', 5867), ('182626', 5700), ('303768', 5651), ('178566', 5169), ('7328', 5135), ('622910', 5122), ('339440', 5052), ('16493', 4878), ('81232', 4835), ('24729', 4770), ('21626', 4768), ('7641', 4629), ('244673', 4532), ('191130', 4517), ('265074', 4501), ('327312', 4430), ('514356', 4416), ('unknown', 4267), ('130682', 4132), ('21329', 4039)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 780 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[10] Processing chunk #11 | n(ts): 983769, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=476 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 476 common codes from the df_extern:\n",
      "['823799', '30130', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '63313', '62372', '7328', '557520', '31427']\n",
      "\n",
      "(balance_data_incr) Added n=352 cases to code=128413\n",
      "(balance_data_incr) Added n=4 cases to code=143388\n",
      "(balance_data_incr) Added n=162 cases to code=17541\n",
      "(balance_data_incr) Added n=33 cases to code=191411\n",
      "(balance_data_incr) Added n=35 cases to code=20644\n",
      "(balance_data_incr) Added n=155 cases to code=237610\n",
      "(balance_data_incr) Added n=14 cases to code=264507\n",
      "(balance_data_incr) Added n=21 cases to code=304337\n",
      "(balance_data_incr) Added n=467 cases to code=327312\n",
      "(balance_data_incr) Added n=5 cases to code=36830\n",
      "(balance_data_incr) Added n=116 cases to code=45427\n",
      "(balance_data_incr) Added n=1 cases to code=505511\n",
      "(balance_data_incr) Added n=24 cases to code=60855\n",
      "(balance_data_incr) Added n=397 cases to code=7641\n",
      "(balance_data_incr) Added n=468 cases to code=81232\n",
      "(balance_data_incr) Added n=21 cases to code=98426\n",
      "(balance_data_incr) Added n=475 cases in total | n_miss:257 ... #\n",
      "... missed (n=257):\n",
      "['451765', '115659', '744441', '79095', '487967', '426171', '303842', '81372', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355', '320184']\n",
      "\n",
      "... hit (n=475):\n",
      "['30130', '823799', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '33902', '63313', '62372', '7328', '557520', '31427']\n",
      "\n",
      "(balance_data) N_extra: 31421\n",
      "[10] size: 983769 -> 1015190\n",
      "[10] size(codes) < 5872 (n=623): \n",
      "[('178566', 5700), ('622910', 5676), ('7328', 5605), ('339440', 5581), ('16493', 5405), ('81232', 5303), ('21626', 5295), ('24729', 5261), ('191130', 5056), ('7641', 5026), ('244673', 4952), ('265074', 4920), ('514356', 4903), ('327312', 4897), ('130682', 4524), ('21329', 4429), ('50484', 4387), ('unknown', 4267), ('128413', 4225), ('339358', 4221)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 790 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[11] Processing chunk #12 | n(ts): 1015190, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=475 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 475 common codes from the df_extern:\n",
      "['30130', '823799', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '110908', '63313', '17434', '7328', '62372']\n",
      "\n",
      "(balance_data_incr) Added n=434 cases to code=128413\n",
      "(balance_data_incr) Added n=9 cases to code=143388\n",
      "(balance_data_incr) Added n=377 cases to code=206243\n",
      "(balance_data_incr) Added n=180 cases to code=237610\n",
      "(balance_data_incr) Added n=13 cases to code=264507\n",
      "(balance_data_incr) Added n=27 cases to code=30403\n",
      "(balance_data_incr) Added n=228 cases to code=326249\n",
      "(balance_data_incr) Added n=367 cases to code=369165\n",
      "(balance_data_incr) Added n=18 cases to code=509562\n",
      "(balance_data_incr) Added n=35 cases to code=61747\n",
      "(balance_data_incr) Added n=34 cases to code=76919\n",
      "(balance_data_incr) Added n=143 cases to code=81240\n",
      "(balance_data_incr) Added n=474 cases in total | n_miss:258 ... #\n",
      "... missed (n=258):\n",
      "['451765', '115659', '744441', '110064', '79095', '424838', '487967', '426171', '303842', '81372', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741']\n",
      "\n",
      "... hit (n=474):\n",
      "['30130', '823799', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '110908', '33902', '17434', '63313', '62372', '7328']\n",
      "\n",
      "(balance_data) N_extra: 30768\n",
      "[11] size: 1015190 -> 1045958\n",
      "[11] size(codes) < 5872 (n=619): \n",
      "[('16493', 5871), ('21626', 5779), ('81232', 5753), ('24729', 5732), ('191130', 5607), ('7641', 5512), ('265074', 5408), ('244673', 5390), ('327312', 5364), ('514356', 5331), ('130682', 4907), ('50484', 4772), ('21329', 4728), ('128413', 4659), ('339358', 4624), ('7096', 4304), ('20958', 4275), ('206243', 4273), ('unknown', 4267), ('483784', 4211)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 821 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[12] Processing chunk #13 | n(ts): 1045958, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=476 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 476 common codes from the df_extern:\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '63313', '7328', '62372', '557520', '31427', '28233']\n",
      "\n",
      "(balance_data_incr) Added n=45 cases to code=146282\n",
      "(balance_data_incr) Added n=65 cases to code=17541\n",
      "(balance_data_incr) Added n=38 cases to code=191411\n",
      "(balance_data_incr) Added n=315 cases to code=206243\n",
      "(balance_data_incr) Added n=17 cases to code=303925\n",
      "(balance_data_incr) Added n=230 cases to code=326249\n",
      "(balance_data_incr) Added n=381 cases to code=369165\n",
      "(balance_data_incr) Added n=119 cases to code=45427\n",
      "(balance_data_incr) Added n=2 cases to code=505552\n",
      "(balance_data_incr) Added n=95 cases to code=544346\n",
      "(balance_data_incr) Added n=22 cases to code=60822\n",
      "(balance_data_incr) Added n=14 cases to code=7690\n",
      "(balance_data_incr) Added n=119 cases to code=81232\n",
      "(balance_data_incr) Added n=2 cases to code=99006\n",
      "(balance_data_incr) Added n=475 cases in total | n_miss:257 ... #\n",
      "... missed (n=257):\n",
      "['451765', '115659', '384834', '744441', '79095', '487967', '303842', '81372', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355', '320184']\n",
      "\n",
      "... hit (n=475):\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '33902', '63313', '62372', '7328', '557520', '31427', '28233']\n",
      "\n",
      "(balance_data) N_extra: 26913\n",
      "[12] size: 1045958 -> 1072871\n",
      "[12] size(codes) < 5872 (n=613): \n",
      "[('327312', 5861), ('514356', 5842), ('265074', 5835), ('244673', 5796), ('130682', 5327), ('50484', 5185), ('21329', 5128), ('339358', 5047), ('128413', 5039), ('7096', 4695), ('20958', 4598), ('483784', 4594), ('206243', 4588), ('108860', 4436), ('369165', 4406), ('unknown', 4267), ('312017', 4203), ('507962', 4004), ('542183', 3962), ('57703', 3919)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 765 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[13] Processing chunk #14 | n(ts): 1072871, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=479 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 479 common codes from the df_extern:\n",
      "['823799', '30130', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '33902', '110908', '63313', '7328', '62372', '557520', '31427']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(balance_data_incr) Added n=9 cases to code=122861\n",
      "(balance_data_incr) Added n=10 cases to code=143081\n",
      "(balance_data_incr) Added n=108 cases to code=205070\n",
      "(balance_data_incr) Added n=139 cases to code=28712\n",
      "(balance_data_incr) Added n=61 cases to code=322156\n",
      "(balance_data_incr) Added n=1 cases to code=351684\n",
      "(balance_data_incr) Added n=85 cases to code=437277\n",
      "(balance_data_incr) Added n=4 cases to code=490243\n",
      "(balance_data_incr) Added n=52 cases to code=54031\n",
      "(balance_data_incr) Added n=6 cases to code=602797\n",
      "(balance_data_incr) Added n=17 cases to code=7021\n",
      "(balance_data_incr) Added n=158 cases to code=81224\n",
      "(balance_data_incr) Added n=1 cases to code=96644\n",
      "(balance_data_incr) Added n=478 cases in total | n_miss:254 ... #\n",
      "... missed (n=254):\n",
      "['451765', '115659', '384834', '744441', '487967', '303842', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355', '320184', '461285', '67702']\n",
      "\n",
      "... hit (n=478):\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '110908', '33902', '63313', '62372', '7328', '557520', '31427']\n",
      "\n",
      "(balance_data) N_extra: 25061\n",
      "[13] size: 1072871 -> 1097932\n",
      "[13] size(codes) < 5872 (n=609): \n",
      "[('130682', 5738), ('50484', 5594), ('21329', 5588), ('128413', 5455), ('339358', 5445), ('7096', 5127), ('20958', 4998), ('483784', 4976), ('206243', 4945), ('108860', 4772), ('369165', 4771), ('312017', 4600), ('507962', 4357), ('unknown', 4267), ('542183', 4250), ('57703', 4173), ('81018', 4141), ('141358', 4092), ('322867', 3826), ('44982', 3792)]\n",
      "\n",
      "(resolve_duplicate) n0: 1000000 =?= n1: 1000000\n",
      "(resolve_duplicate) Found 791 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[14] Processing chunk #15 | n(ts): 1097932, n(tsi): 1000000 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=482 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 482 common codes from the df_extern:\n",
      "['823799', '30130', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '33902', '110908', '63313', '7328', '62372', '557520', '31427']\n",
      "\n",
      "(balance_data_incr) Added n=16 cases to code=122861\n",
      "(balance_data_incr) Added n=10 cases to code=143081\n",
      "(balance_data_incr) Added n=7 cases to code=205211\n",
      "(balance_data_incr) Added n=72 cases to code=22848\n",
      "(balance_data_incr) Added n=18 cases to code=25395\n",
      "(balance_data_incr) Added n=123 cases to code=30262\n",
      "(balance_data_incr) Added n=74 cases to code=31682\n",
      "(balance_data_incr) Added n=59 cases to code=354621\n",
      "(balance_data_incr) Added n=51 cases to code=453530\n",
      "(balance_data_incr) Added n=33 cases to code=495499\n",
      "(balance_data_incr) Added n=285 cases to code=542183\n",
      "(balance_data_incr) Added n=25 cases to code=60822\n",
      "(balance_data_incr) Added n=13 cases to code=7021\n",
      "(balance_data_incr) Added n=42 cases to code=81174\n",
      "(balance_data_incr) Added n=6 cases to code=96107\n",
      "(balance_data_incr) Added n=481 cases in total | n_miss:251 ... #\n",
      "... missed (n=251):\n",
      "['451765', '115659', '384834', '744441', '487967', '426171', '303842', '397786', '530170', '204537', '151522', '305524', '111567', '422410', '505628', '142364', '30741', '345355', '320184', '461285']\n",
      "\n",
      "... hit (n=481):\n",
      "['30130', '823799', '52472', '594192', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '40865', '7120', '110908', '33902', '63313', '62372', '7328', '557520', '31427']\n",
      "\n",
      "(balance_data) N_extra: 23528\n",
      "[14] size: 1097932 -> 1121460\n",
      "[14] size(codes) < 5872 (n=606): \n",
      "[('339358', 5819), ('128413', 5816), ('7096', 5484), ('483784', 5348), ('20958', 5343), ('206243', 5269), ('369165', 5126), ('108860', 5117), ('312017', 4840), ('507962', 4628), ('542183', 4535), ('57703', 4435), ('81018', 4420), ('141358', 4363), ('unknown', 4267), ('44982', 4095), ('322867', 3998), ('30247', 3911), ('28894', 3851), ('7146', 3834)]\n",
      "\n",
      "(resolve_duplicate) n0: 73091 =?= n1: 73091\n",
      "(resolve_duplicate) Found 349 duplicate rows wrt cols: ['test_result_loinc_code']\n",
      "(canonicalize) Operations> fillna, dehyphenate, replace_values, trim_tail, fill_others\n",
      "(canonicalize) Focus only on target labels (n=733), labeling the rest as other\n",
      "[15] Processing chunk #16 | n(ts): 1121460, n(tsi): 73091 ...\n",
      "(balance_data_incr) n_baseline=5872\n",
      "(balance_data_incr) Found n=734 unique codes from source | nc=394 unique codes from external\n",
      "... found 0=?=0 extra codes from the df_extern:\n",
      "[]\n",
      "\n",
      "... found 394 common codes from the df_extern:\n",
      "['30130', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '7120', '33902', '63313', '7328', '557520', '31427', '28233', '490243', '57943', '7344', '622928', '884478']\n",
      "\n",
      "(balance_data_incr) Added n=1 cases to code=155465\n",
      "(balance_data_incr) Added n=19 cases to code=204479\n",
      "(balance_data_incr) Added n=1 cases to code=23366\n",
      "(balance_data_incr) Added n=1 cases to code=264788\n",
      "(balance_data_incr) Added n=10 cases to code=295410\n",
      "(balance_data_incr) Added n=7 cases to code=30536\n",
      "(balance_data_incr) Added n=6 cases to code=51300\n",
      "(balance_data_incr) Added n=6 cases to code=57927\n",
      "(balance_data_incr) Added n=2 cases to code=63032\n",
      "(balance_data_incr) Added n=1 cases to code=7385\n",
      "(balance_data_incr) Added n=5 cases to code=81166\n",
      "(balance_data_incr) Added n=393 cases in total | n_miss:339 ... #\n",
      "... missed (n=339):\n",
      "['823799', '451765', '384834', '52472', '110064', '744441', '79095', '424838', '487967', '51177', '594192', '831008', '426171', '303842', '81372', '397786', '530170', '204537', '151522', '305524']\n",
      "\n",
      "... hit (n=393):\n",
      "['30130', '7021', '304469', '130682', '58115', '191395', '45484', '7898', '7120', '33902', '63313', '7328', '557520', '31427', '28233', '490243', '57943', '7344', '622928', '884478']\n",
      "\n",
      "(balance_data) N_extra: 2039\n",
      "[15] size: 1121460 -> 1123499\n",
      "[15] size(codes) < 5872 (n=606): \n",
      "[('339358', 5851), ('128413', 5842), ('7096', 5519), ('20958', 5385), ('483784', 5385), ('206243', 5301), ('369165', 5165), ('108860', 5143), ('312017', 4879), ('507962', 4663), ('542183', 4559), ('57703', 4462), ('81018', 4442), ('141358', 4389), ('unknown', 4267), ('44982', 4124), ('322867', 4017), ('30247', 3930), ('28894', 3873), ('7146', 3856)]\n",
      "\n",
      "(t_stratify) At last, we could not find a match for n=731 codes among nl=731 low-sample-size labels:\n",
      "{'823799', '30130', '384834', '52472', '594192', '7021', '304469', '130682', '58115', '45484', '191395', '7898', '40865', '7120', '7732', '33902', '110908', '17434', '63313', '7328', '62372', '557520', '505586', '28233', '31427', '490243', '57943', '115261', '882944', '7344', '622928', '884478', '295410', '301804', '311472', '154120', '81018', '332569', '21600', '323238', '97287', '240077', '15586', '21626', '483784', '33969', '24729', '7385', '82198', '462168', '312082', '108860', '63032', '381772', '143388', '347047', '882936', '75007', '134999', '223149', '632117', '142786', '429316', '19885', '18358', '203935', '18416', '20289', '330373', '204073', '139816', '33944', '50120', '57828', '791863', '18341', '331942', '104661', '823781', '193433', '178566', '66902', '602565', '325852', '452243', '264747', '305227', '382507', '57927', '174334', '19208', '161281', '596155', '302398', '28886', '96644', '206060', '139501', '79178', '10058', '264499', '79053', '305250', '150748', '7062', '139519', '110387', '7302', '31419', '169987', '57687', '169151', '56390', '197681', '31385', '195933', '64717', '178640', '264788', '315887', '264663', '336677', '264507', '542183', '67421', '265231', '139832', '27318', '122358', '461541', '274167', '19687', '312017', '226357', '19596', '25148', '514877', '241083', '329987', '264531', '339358', '62489', '243311', '110114', '238717', '203943', '30494', '24653', '24687', '495416', '161265', '333583', '223123', '18846', '269712', '148049', '84999', '597054', '191957', '143081', '583591', '823765', '28746', '747741', '143149', '451765', '744441', '110064', '424838', '51177', '303768', '68338', '285411', '530170', '204537', '7864', '151522', '422410', '427682', '111567', '305524', '142364', '487942', '345355', '30741', '461285', '320184', '96107', '385187', '7112', '327767', '177915', '149591', '22848', '81166', '61747', '7138', '31674', '205211', '20644', '192526', '577478', '59592', '162289', '28654', '155465', '196618', '163485', '747931', '223198', '23366', '302117', '7187', '19711', '772079', '302505', '20396', '27771', '728592', '473652', '178152', '257006', '157743', '25395', '492967', '505537', '131698', '121855', '265074', '80143', '56457', '161901', '241240', '30247', '204081', '264440', '908947', '28894', '7765', '7773', '218404', '20933', '51912', '509570', '30403', '507962', '516492', '7146', '264994', '29512', '17442', '486423', '30502', '295980', '51268', '112821', '495499', '82537', '322156', '347005', '204057', '98426', '154328', '45765', '7831', '18093', '519132', '7369', '223222', '406611', '163626', '146282', '483453', '264853', '56853', '26971', '38794', '149575', '831008', '45377', '22764', '214163', '514372', '139923', '30163', '195586', '452854', '110775', '169573', '103341', '36830', '7518', '107011', '51813', '736546', '25718', '505594', '178137', '304287', '24661', '462663', '64204', '533182', '223164', '7989', '304337', '825141', '622381', '108340', '303503', '58131', '139550', '68965', '110510', '473835', '25015', '424820', '521302', '273532', '33894', '29553', '139956', '25320', '122861', '162354', '7377', '50484', '96610', '5056360', '109009', '223271', '771477', '141358', '354621', '57703', '51896', '493114', '60855', '622910', '24679', '298935', '519140', '161927', '204164', '139527', '19893', '19869', '54031', '285395', '80614', '539627', '21576', '148692', '884486', '717744', '62810', '885178', '312041', '423327', '160119', '533265', '21642', '544346', '52092', '60756', '285403', '23390', '422543', '178111', '30262', '134577', '426171', '81125', '397786', '823773', '203927', '192955', '505628', '30841', '67702', '52217', '194290', '24984', '244673', '206243', '7682', '327338', '29868', '339143', '195503', '369165', '39347', '17426', '80689', '303610', '327692', '22368', '322867', '58040', '112771', '251488', '93187', '71555', '17590', '602797', '17830', '59469', '58032', '285452', '37192', '460980', '182824', '690487', '169334', '150144', '191502', '7641', '265116', '80937', '170886', '110130', '59055', '20859', '265157', '339101', '332551', '95927', '51953', '461277', '326231', '142729', '298927', '57844', '451617', '728626', '162370', '159756', '51300', '297713', '453878', '293001', '487678', '304501', '381806', '390179', '196428', '17541', '584292', '355594', '204966', '28571', '30346', '327601', '823807', '45427', '178616', '63016', '182626', '7096', '206649', '24588', '191411', '241109', '462176', '30916', '326249', '115808', '333138', '31732', '109926', '150136', '128413', '205088', '483982', '25056', '505610', '205708', '183145', '285429', '115725', '433045', '156935', '139949', '81729', '53728', '351684', '81240', '82362', '30973', '139451', '28712', '349993', '196592', '139642', '139808', '357418', '005025', '59014', '142976', '31815', '264846', '28902', '76919', '82206', '35436', '17435', '21329', '71001', '296095', '45518', '304519', '17517', '178194', '122275', '62760', '747956', '237610', '882934', '56432', '149799', '23457', '110544', '502211', '20008', '437277', '156679', '701417', '64634', '192997', '752279', '19620', '204545', '428102', '7708', '162511', '303925', '265058', '422428', '133629', '21618', '51797', '93179', '32987', '95976', '514356', '264648', '19638', '728600', '533166', '51573', '29652', '57679', '58024', '716951', '196444', '82511', '303644', '550513', '60822', '505511', '748632', '241133', '724864', '103317', '39685', '755082', '169490', '51938', '448134', '33498', '61895', '115659', '20750', '172841', '487967', '105015', '79095', '18697', '81224', '7310', '303842', '81372', '134585', '481598', '191130', '150169', '111252', '57992', '505578', '28282', '139907', '23242', '80945', '16493', '7633', '487926', '112599', '495036', '216960', '181826', '497818', '191239', '53587', '80100', '51599', '330514', '254284', '108399', '31377', '20958', '191619', '112532', '80994', '28621', '143164', '99006', '509562', '57786', '204552', '514802', '183095', '205070', '19901', '24695', '21188', '304717', '514869', '98301', '82644', '7401', '142778', '44859', '339440', '192708', '139899', '204479', '25007', '162503', '551598', '7351', '162339', '268748', '531152', '736553', '487959', '21436', '6304', '7492', '347146', '162297', '661496', '568881', '327312', '214825', '505552', '7427', '312900', '81380', '20917', '236562', '486431', '316273', '7872', '45443', '611517', '772020', '825232', '29918', '425959', '226381', '433961', '138016', '303859', '356188', '29900', '183962', '453530', '28852', '205450', '142513', '265249', '825216', '640847', '7534', '825208', '487934', '150672', '115790', '25023', '18259', '51995', '81174', '57976', '169359', '384453', '81299', '162057', '205674', '139543', '216135', '78857', '7856', '30536', '19752', '299016', '634642', '44917', '128512', '52449', '31682', '58214', '265082', '251454', '192831', '7047', '59022', '225805', '30510', '32896', '28688', '44982', '30940', '51961', '514786', '7690', '7880', '81232', '62992', '58941', '433052', '17988'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(save_data) Saved dataframe (dim=(1123499, 128)) to:\n",
      "/Users/barnett/Documents/work/loinc_predictor/data/andromeda-pond-hepatitis-c-balanced.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nOutput\\n------\\n   ts: balanced training data; well... as balaned as possible because external data may not be able to supply sufficient \\n       data for a subset of the classes/loincs\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from analyzer import balance_data_incr, load_data_incr, stratify\n",
    "from transformer import resolve_duplicate\n",
    "import loinc as lc\n",
    "\n",
    "# run here or just load the curated data generated by analyzer.t_stratify()\n",
    "tLoad = False\n",
    "tSave = True\n",
    "\n",
    "ts = ts0\n",
    "ds = stratify(ts, col='test_result_loinc_code', ascending=False)\n",
    "print(\"(balance_classes) data size distribution:\\n{}\\n\".format(ds[:25]))\n",
    "ds = [(code, size) for code, size in ds if not code in lc.LoincTSet.non_codes]\n",
    "max_size = ds[0][1] # ds[2][1]\n",
    "codes_low_sz = set([code for code, size in ds if size < max_size])\n",
    "print(\"(balance_classes) We have n={} with low sample size (< {})\".format(len(codes_low_sz), max_size))\n",
    "\n",
    "if tLoad: \n",
    "    input_file=f\"andromeda-pond-{cohort}-balanced.csv\"\n",
    "    ts = load_data(input_file=input_file, warn_bad_lines=False)\n",
    "    # ts = ts.drop_duplicates(keep='last')  # drop duplicates \n",
    "    # ts = lc.canonicalize(ts, col_target=col_target, token_missing=token_default, target_labels=loinc_set)\n",
    "    assert lc.is_canonicalized(ts, col_target=col_target, token_missing=token_default, target_labels=loinc_set)\n",
    "    \n",
    "else: \n",
    "    # max_size = 1000\n",
    "    input_file = f\"andromeda-pond-{cohort}-loinc.csv\"\n",
    "    codes = set(loinc_set)\n",
    "    codes_hit = set([])\n",
    "    for i, tsi in enumerate(load_data_incr(input_file=input_file, chunksize=1000000, warn_bad_lines=False)): \n",
    "        N0 = ts.shape[0]\n",
    "        # tsi = tsi.drop_duplicates(keep='last')  # drop duplicates \n",
    "        tsi = resolve_duplicate(tsi)\n",
    "        tsi = lc.canonicalize(tsi, col_target=col_target, token_missing=token_default, target_labels=loinc_set)\n",
    "        print(\"[{}] Processing chunk #{} | n(ts): {}, n(tsi): {} ...\".format(i, i+1, N0, tsi.shape[0]))\n",
    "\n",
    "        ts_incr, hit, missed = balance_data_incr(df=ts, df_extern=tsi, n_samples=max_size, col=col_target)\n",
    "        if not ts_incr.empty: ts = pd.concat([ts, ts_incr])\n",
    "            \n",
    "        # --- analysis --- \n",
    "        N = ts.shape[0]\n",
    "        codes_hit.union(hit) # still has this many codes without a match \n",
    "\n",
    "        print(f\"[{i}] size: {N0} -> {N}\")\n",
    "        ds = stratify(ts, col='test_result_loinc_code', ascending=False)\n",
    "        ds = [(code, size) for code, size in ds if size < max_size]\n",
    "        print(\"[{}] size(codes) < {} (n={}): \\n{}\\n\".format(i, max_size, len(ds), ds[:20]))\n",
    "\n",
    "    codes_missed = codes_low_sz - codes_hit  \n",
    "    print(\"(t_stratify) At last, we could not find a match for n={} codes among nl={} low-sample-size labels:\\n{}\\n\".format(\n",
    "        len(codes_missed), len(codes_low_sz), codes_missed))  \n",
    "    \n",
    "    # down sample control data (very often the negative examples are too huge)\n",
    "\n",
    "    if tSave: \n",
    "        \n",
    "        # should not have duplicates at this point (due to resolve_duplicate() call)\n",
    "        # ts = ts.drop_duplicates(keep='last')  # drop duplicates \n",
    "        \n",
    "        output_file = f\"andromeda-pond-{cohort}-balanced.csv\"\n",
    "        save_data(ts, output_file=output_file)\n",
    "\n",
    "\"\"\"\n",
    "Output\n",
    "------\n",
    "   ts: balanced training data; well... as balaned as possible because external data may not be able to supply sufficient \n",
    "       data for a subset of the classes/loincs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformation\n",
    "\n",
    "note: patient_date_of_birth => age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> age: [60 34 21 84 69 78 45 56 43 24]\n"
     ]
    }
   ],
   "source": [
    "from transformer import to_age\n",
    "from analyzer import col_values\n",
    "# from loinc import FeatureSet\n",
    "\n",
    "to_age(ts)\n",
    "values = col_values(ts, col='age', n=10)\n",
    "print(\"> age: {}\".format(values))\n",
    "\n",
    "# resolve_duplicate() call adds a new column: count (of duplicates)\n",
    "assert 'count' in ts.columns\n",
    "\n",
    "# datatime columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Features and Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Given features set:\n",
      "['age', 'patient_gender', 'patient_state', 'patient_bill_type', 'fasting', 'performing_organization_id', 'receiving_organization_id', 'test_result_status', 'test_order_code', 'test_order_name', 'test_result_code', 'test_result_name', 'test_result_value', 'test_result_range', 'test_result_abnormal_flag', 'test_result_reference_range', 'test_result_units_of_measure', 'test_result_comments', 'test_cpt_code', 'panel_order_code', 'panel_order_name', 'meta_sender_name', 'medivo_test_result_type', 'count']\n",
      "\n",
      "> Final feature set (nf=24):\n",
      "{'test_result_status', 'count', 'test_result_comments', 'test_result_reference_range', 'test_result_value', 'panel_order_name', 'test_result_name', 'test_result_range', 'receiving_organization_id', 'test_order_code', 'panel_order_code', 'meta_sender_name', 'patient_gender', 'patient_state', 'medivo_test_result_type', 'test_result_abnormal_flag', 'fasting', 'performing_organization_id', 'test_order_name', 'test_result_units_of_measure', 'test_result_code', 'patient_bill_type', 'test_cpt_code', 'age'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nOutput\\n------\\n   dfX \\n   dfy\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tCategorify = False\n",
    "tDropHighMissing = False # drop columns with high rate of missing values\n",
    "p_null = 0.9\n",
    "token_default = token_missing = 'unknown'\n",
    "\n",
    "df = ts # ... :)\n",
    "\n",
    "# V = list(feature_lookup.keys())\n",
    "V = cont_cols + cat_cols + derived_cols\n",
    "L = target_cols\n",
    "dfX = df[V]\n",
    "dfy = df[L]\n",
    "\n",
    "print(\"> Given features set:\\n{}\\n\".format(V))\n",
    "\n",
    "assert np.sum(dfy[target_cols[0]].isnull()) == 0\n",
    "\n",
    "# drop columns/vars with too many missing values \n",
    "N = dfX.shape[0]\n",
    "n_thresh = int(N * p_null)\n",
    "nf0 = nf = dfX.shape[1]\n",
    "fset0 = set(dfX.columns.values)\n",
    "\n",
    "if tDropHighMissing: \n",
    "    dfX = dfX[dfX.columns[dfX.isnull().mean() < p_null]]\n",
    "    fset = set(dfX.columns.values)\n",
    "    nf = dfX.shape[1]\n",
    "    print(\"> Dropped n={} features:\\n{}\\n\".format(nf-nf0, fset0-fset))\n",
    "    \n",
    "fset = set(dfX.columns.values)\n",
    "print(\"> Final feature set (nf={}):\\n{}\\n\".format(nf, fset))\n",
    "\n",
    "# fill in missing values (also see default_values)\n",
    "dfX.fillna(value=token_default, inplace=True)\n",
    "#################################################\n",
    "# Convert our three categorical columns to category dtypes.\n",
    "\n",
    "cat_cols = [cat for cat in cat_cols if cat in dfX.columns]\n",
    "cont_cols = [c for c in cont_cols if c in dfX.columns]\n",
    "\n",
    "\"\"\"\n",
    "Output\n",
    "------\n",
    "   dfX \n",
    "   dfy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(encoder_vars) low card vars (n=['fasting', 'meta_sender_name', 'patient_gender']):\n",
      "3\n",
      " ... high card vars (n=['test_result_status', 'patient_state', 'medivo_test_result_type', 'test_result_abnormal_flag', 'test_result_comments', 'test_result_reference_range', 'performing_organization_id', 'test_order_name', 'test_result_units_of_measure', 'test_result_value', 'test_result_code', 'panel_order_name', 'test_result_name', 'test_result_range', 'receiving_organization_id', 'test_order_code', 'patient_bill_type', 'panel_order_code', 'test_cpt_code']):\n",
      "19\n",
      "\n",
      "... transforming var: patient_gender ...\n",
      "... transforming var: patient_state ...\n",
      "... transforming var: patient_bill_type ...\n",
      "... transforming var: fasting ...\n",
      "... transforming var: performing_organization_id ...\n",
      "... transforming var: receiving_organization_id ...\n",
      "... transforming var: test_result_status ...\n",
      "... transforming var: test_order_code ...\n",
      "... transforming var: test_order_name ...\n",
      "... transforming var: test_result_code ...\n",
      "... transforming var: test_result_name ...\n",
      "... transforming var: test_result_value ...\n",
      "... transforming var: test_result_range ...\n",
      "... transforming var: test_result_abnormal_flag ...\n",
      "... transforming var: test_result_reference_range ...\n",
      "... transforming var: test_result_units_of_measure ...\n",
      "... transforming var: test_result_comments ...\n",
      "... transforming var: test_cpt_code ...\n",
      "... transforming var: panel_order_code ...\n",
      "... transforming var: panel_order_name ...\n",
      "... transforming var: meta_sender_name ...\n",
      "... transforming var: medivo_test_result_type ...\n",
      "> After variable encoding we have dim(dfX): (1123499, 243) | nf: 24 -> 243\n",
      "> New feature set:\n",
      "Index(['age', 'patient_gender_1', 'patient_gender_2', 'patient_gender_3',\n",
      "       'patient_state_0', 'patient_state_1', 'patient_state_2',\n",
      "       'patient_state_3', 'patient_state_4', 'patient_state_5',\n",
      "       ...\n",
      "       'medivo_test_result_type_3', 'medivo_test_result_type_4',\n",
      "       'medivo_test_result_type_5', 'medivo_test_result_type_6',\n",
      "       'medivo_test_result_type_7', 'medivo_test_result_type_8',\n",
      "       'medivo_test_result_type_9', 'medivo_test_result_type_10',\n",
      "       'medivo_test_result_type_11', 'count'],\n",
      "      dtype='object', length=243)\n",
      "\n",
      "meta_sender_name                 test_order_name    test_result_name test_result_loinc_code test_result_units_of_measure\n",
      "         Athena      Comp. Metabolic Panel (14)          ALT (SGPT)                  17426                          NaN\n",
      "         Athena                   HCV FibroSure      ALT (SGPT) P5P                  17434                          NaN\n",
      "         Saturn             HEPATIC LIVER PANEL     TOTAL BILIRUBIN                  19752                        MG/DL\n",
      "         Saturn            Complete Blood Count  Basophils Absolute                   7047                     1000/cmm\n",
      "         Saturn   COMPREHENSIVE METABOLIC PANEL      CALC BUN/CREAT                  30973                        RATIO\n",
      "         Apollo           BASIC METABOLIC PANEL           POTASSIUM                  28233                       mmol/L\n",
      "         Athena  CBC With Differential/Platelet              Lymphs                   7369                          NaN\n",
      "         Athena      Hepatic Function Panel (7)          ALT (SGPT)                  17426                          NaN\n",
      "         Athena                   HCV FibroSure            Comment:                 772020                          NaN\n",
      "         Apollo         CBC (Includes Diff/Plt)                 RBC                   7898                     Mill/mcL\n"
     ]
    }
   ],
   "source": [
    "from transformer import encode_vars \n",
    "from loinc import FeatureSet\n",
    "# high_card_cols = FeatureSet.high_card_cols\n",
    "nf0 = dfX.shape[1]\n",
    "dfX = encode_vars(dfX, fset=cat_cols, high_card_cols=high_card_cols)\n",
    "print(\"> After variable encoding we have dim(dfX): {} | nf: {} -> {}\".format(dfX.shape, nf0, dfX.shape[1]))\n",
    "print(\"> New feature set:\\n{}\\n\".format(dfX.columns))\n",
    "print(df[representative_cols].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Low sample size classes | n=489 (< 1000)\n",
      "> Extreme low sample size classes | n=176 (< 10)\n",
      "> n_matched: 128 | max_size: 5872\n",
      "[356188] -> 1\n",
      "[206649] -> 1\n",
      "[223123] -> 1\n",
      "[156679] -> 1\n",
      "[530170] -> 1\n",
      "[264663] -> 1\n",
      "[154120] -> 1\n",
      "[162511] -> 1\n",
      "[196618] -> 1\n",
      "[302505] -> 1\n",
      "[724864] -> 1\n",
      "[634642] -> 1\n",
      "[336677] -> 1\n",
      "[161265] -> 1\n",
      "[451765] -> 1\n",
      "> sizes: [('17426', 5872), ('19752', 5872), ('7047', 5872), ('30973', 5872), ('28233', 5872), ('7369', 5872), ('7898', 5872), ('21600', 5872), ('7708', 5872), ('20933', 5872), ('339143', 5872), ('67686', 5872), ('20859', 5872), ('7773', 5872), ('7112', 5872), ('7187', 5872), ('7138', 5872), ('24984', 5872), ('28571', 5872), ('66902', 5872)]\n",
      "> Sample sizes | Top N=5 codes:\n",
      "[('17426', 5872), ('19752', 5872), ('7047', 5872), ('30973', 5872), ('28233', 5872)]\n",
      "\n",
      "> Sample sizss | Last N=5 codes:\n",
      "[('206060', 1), ('162339', 1), ('64204', 1), ('80945', 1), ('162057', 1)]\n",
      "\n",
      "(encode_labels) sample size: Counter({0: 1117627, 1: 5872})\n"
     ]
    }
   ],
   "source": [
    "from analyzer import encode_labels, summarize_dict, get_sample_sizes\n",
    "import collections, operator\n",
    "\n",
    "# verify\n",
    "assert dfX.shape[0] == dfy.shape[0], \"> dim(dfX): {} | dfy.cols: {}\".format(dfX.shape, dfy.columns.values)\n",
    "\n",
    "codebook={'pos': 1, 'neg': 0, '+': 1, '-': 0}\n",
    "\n",
    "# choose the one with a large sample size as 'positive'\n",
    "col_label = 'test_result_loinc_code' # strings\n",
    "\n",
    "topn = 5\n",
    "sizes = get_sample_sizes(dfy[col_label])\n",
    "# ... sizes: (loinc) label -> sample size\n",
    "# print(\"> n(sizes): {}\".format(len(sizes)))  # 734 for cohort='hepatitis-c'\n",
    "\n",
    "# Q: How many classes/codes have less than N instances? \n",
    "N_low = 1000\n",
    "n_low = sum(1 for l, c in sizes.items() if c < N_low)\n",
    "print(\"> Low sample size classes | n={} (< {})\".format(n_low, N_low))\n",
    "\n",
    "N_elow = 10\n",
    "n_elow = sum(1 for l, c in sizes.items() if c < N_elow)\n",
    "print(\"> Extreme low sample size classes | n={} (< {})\".format(n_elow, N_elow))\n",
    "\n",
    "# Q: How many classes/codes were able to match the most enriched class in terms of sample size (e.g. 5707)? \n",
    "eps = 10\n",
    "n_matched = sum(1 for l, c in sizes.items() if c >= max_size-eps)\n",
    "print(\"> n_matched: {} | max_size: {}\".format(n_matched, max_size))\n",
    "\n",
    "# sort by values\n",
    "sizes_sorted = sorted(sizes.items(), key=operator.itemgetter(1))\n",
    "summarize_dict(sizes, topn=15, sort_=True)\n",
    "\n",
    "print(\"> sizes: {}\".format(sizes.most_common(20)))\n",
    "most_sample_sizes = sizes.most_common(topn)  # take(topn, sizes.items())\n",
    "print(\"> Sample sizes | Top N={} codes:\\n{}\\n\".format(topn, most_sample_sizes))\n",
    "least_sample_sizes = sizes.most_common()[:-topn-1:-1]\n",
    "print(\"> Sample sizss | Last N={} codes:\\n{}\\n\".format(topn, least_sample_sizes))\n",
    "\n",
    "# test\n",
    "target = most_sample_sizes[0][0]\n",
    "y = encode_labels(dfy, pos_label=target, codebook=codebook, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model Training\n",
    "\n",
    "### 1. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ref\n",
    "---\n",
    "1. pip install feature-selector\n",
    "\n",
    "   https://github.com/WillKoehrsen/feature-selector\n",
    "   \n",
    "   possible dependency \n",
    "      brew install libomp\n",
    "      \n",
    "   <debug> \n",
    "       + RuntimeError: Python is not installed as a framework.\n",
    "          > https://stackoverflow.com/questions/34977388/matplotlib-runtimeerror-python-is-not-installed-as-a-framework\n",
    "   \n",
    "\"\"\"\n",
    "import feature_selector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Save a copy of encoded training set (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(save_data) Saved dataframe (dim=(1123499, 129)) to:\n",
      "/Users/barnett/Documents/work/loinc_predictor/data/andromeda-pond-hepatitis-c-encoded.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tSaveEncodedTSet = True \n",
    "\n",
    "if tSaveEncodedTSet: \n",
    "    output_file = f\"andromeda-pond-{cohort}-encoded.csv\"\n",
    "    save_data(ts, output_file=output_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> dim(X): (1123499, 243), sample(y): ['28233' '28571' '326231' '45443' '7856' '60855' '51797' '10058' '28571'\n",
      " '162297' '7138' '728600' '30163' '264531' '311472' '204081' '542183'\n",
      " '303503' '139808' '33944']\n",
      "(encode_labels) sample size: Counter({0: 1117627, 1: 5872})\n",
      "> sample size | n(+): 5872, n(-): 1117627 | dim(y_encoded): (1123499,)\n",
      "balance_by_downsampling) nl: 2, labels: [0 1] | nf=243\n",
      "... After merging (X, y) => dim(X): (1123499, 244)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "244",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3063\u001b[0m         \"\"\"\n\u001b[0;32m-> 3064\u001b[0;31m         \u001b[0mGet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnearest\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mrequires\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3065\u001b[0m         values that can be subtracted from each other (e.g., not strings or\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 244",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7278f23e7bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_pos\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn_min\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# downsampling majority classes (very often we have too many negative instances)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mX_eff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_eff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbalance_by_downsampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_eff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multiple'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajority_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mn_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcodebook\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcodebook\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"> sample size (after downsampling majority) | n(+): {n_pos}, n(-): {n_neg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/loinc_predictor/analyzer.py\u001b[0m in \u001b[0;36mbalance_by_downsampling\u001b[0;34m(X, y, method, majority_max)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mtsl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNcut\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0munderlying\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcopied\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmade\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpossible\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m             \u001b[0mAdditional\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mno\u001b[0m \u001b[0meffect\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0maccepted\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m             \u001b[0mcompatibility\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0mThe\u001b[0m \u001b[0mtransposed\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2484\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALL\u001b[0m \u001b[0mnan\u001b[0m \u001b[0mrows\u001b[0m \u001b[0mwill\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mwritten\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0merrors\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'strict'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m             \u001b[0mSpecifies\u001b[0m \u001b[0mhow\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdecoding\u001b[0m \u001b[0merrors\u001b[0m \u001b[0mare\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mhandled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m             \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0merrors\u001b[0m \u001b[0margument\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m             \u001b[0mof\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3064\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnearest\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mrequires\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m         values that can be subtracted from each other (e.g., not strings or\n\u001b[0;32m-> 3066\u001b[0;31m         tuples).\n\u001b[0m\u001b[1;32m   3067\u001b[0m         \"\"\"\n\u001b[1;32m   3068\u001b[0m         \u001b[0mleft_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 244"
     ]
    }
   ],
   "source": [
    "import utils_tree, utils_sys, analyzer\n",
    "import collections\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from analyzer import balance_by_downsampling\n",
    "\n",
    "# data transformation\n",
    "col = 'test_result_loinc_code'\n",
    "X, y = dfX.values, dfy[col].values\n",
    "print(\"> dim(X): {}, sample(y): {}\".format(X.shape, np.random.choice(np.unique(y),20) ))\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler() # MinMaxScaler(), StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "n_fold = 5\n",
    "n_min = n_fold\n",
    "\n",
    "# to save performance data\n",
    "header = ['code', 'mean', 'std', 'n_pos']\n",
    "sdict = {h:[] for h in header}\n",
    "for code in loinc_set: \n",
    "    y_eff = analyzer.encode_labels(y, pos_label=code)\n",
    "    \n",
    "    counter = collections.Counter(y_eff)\n",
    "    n_pos, n_neg = counter[codebook['pos']], counter[codebook['neg']]\n",
    "    print(\"> sample size | n(+): {}, n(-): {} | dim(y_encoded): {}\".format(n_pos, n_neg, y_eff.shape))\n",
    "    \n",
    "    if n_pos >= n_min: \n",
    "        # downsampling majority classes (very often we have too many negative instances)\n",
    "        X_eff, y_eff = balance_by_downsampling(X, y_eff, method='multiple', majority_max=3)\n",
    "        n_pos, n_neg = counter[codebook['pos']], counter[codebook['neg']]\n",
    "        print(f\"> sample size (after downsampling majority) | n(+): {n_pos}, n(-): {n_neg}\")\n",
    "        \n",
    "        scores = analyzer.eval_performance(X_eff, y_eff, model=None, cv=n_fold, random_state=53, verbose=1)\n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores)\n",
    "        print(\"> average: {}, std: {}\".format(mean_score, std_score))\n",
    "    else: \n",
    "        print(\"> (positive) sample size too small, n={}\".format(n_pos))\n",
    "        mean_score = -1 \n",
    "        std_score = -1\n",
    "    sdict['code'].append(code)\n",
    "    sdict['mean'].append(mean_score)\n",
    "    sdict['std'].append(std_score)\n",
    "    sdict['n_pos'].append(n_pos)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# save performance dataframe\n",
    "df_perf = DataFrame(sdict, columns=header)\n",
    "df_perf = df_perf.sort_values(by=['mean', ]) # ascending=False\n",
    "analyzer.save_performnace(df, output_dir='result') # output_file/'' (performance-<cohort>.csv)\n",
    "\n",
    "cohort = 'hepatitis-c'\n",
    "output_dir = os.path.join(os.getcwd(), 'result')\n",
    "output_file = f\"performance-{cohort}-2.csv\" \n",
    "output_path = os.path.join(output_dir, output_file)\n",
    "df_perf.to_csv(output_path, sep='|', index=False, header=True)\n",
    "\n",
    "for code, score in zip(df_perf['code'], df_perf['mean']):\n",
    "    print(f\"[{code}] -> {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Memo\n",
    "---- \n",
    "1. performance plot\n",
    "\n",
    "   perplot: https://pypi.org/project/perfplot/\n",
    "\"\"\"\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from analyzer import load_performance\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(6, 20))\n",
    "sns.set_color_codes(\"pastel\")\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "# load performance data\n",
    "cohort = 'hepatitis-c'\n",
    "df_perf = load_performance(input_dir='result', cohort=cohort)\n",
    "print(\"> dim(performance matrix): {}\".format(df_perf.shape))\n",
    "\n",
    "# sort ~ performance scores \n",
    "# df_perf = df_perf.sort_values(by=['mean', ], ascending=False)\n",
    "\n",
    "header = ['code', 'mean', 'std', 'n_pos']\n",
    "codes = df_perf['code']\n",
    "n_codes = len(codes)\n",
    "scores = df_perf['mean']\n",
    "\n",
    "# some statistics\n",
    "score_high = 0.90\n",
    "score_low = 0.50\n",
    "\n",
    "codes_low_sz = df_perf.loc[df_perf['mean'] < 0]['code']\n",
    "codes_scored = df_perf.loc[df_perf['mean'] >= 0]['code']\n",
    "codes_high_score = df_perf.loc[df_perf['mean'] >= score_high]['code']\n",
    "assert n_codes == len(codes_low_sz) + len(codes_scored)\n",
    "\n",
    "print(\"1. Total number of codes: {} | n(low_sample): {}, n(scored):{}, n(high scored):{}\".format(n_codes, \n",
    "   len(codes_low_sz), len(codes_scored), len(codes_high_score)))\n",
    "r_scored = len(codes_scored)/(n_codes+0.0)\n",
    "rh = len(codes_high_score)/(n_codes+0.0)\n",
    "print(\"2. Fraction of scored codes: {}\".format(r_scored))\n",
    "print(\"3. Fraction of highly scored codes: {}\".format(rh))\n",
    "\n",
    "# Effective performance dataframe, ruling out those codes without scores (due to low sample sizes)\n",
    "df_eff = df_perf.loc[df_perf['mean'] >= 0.0]\n",
    "\n",
    "n_offset = 25\n",
    "df_topn = df_eff.sort_values(['mean', ], ascending=False).head(n_offset)\n",
    "df_botn = df_eff.sort_values(['mean', ], ascending=True).head(n_offset)\n",
    "# print(df_botn)\n",
    "\n",
    "# codes = [str(c) for c in df_botn['code'].values]\n",
    "# print('lower codes: {}'.format(codes))\n",
    "# scores = df_botn['mean'].values\n",
    "# print('scores: {}'.format(scores))\n",
    "\n",
    "# top n + bottom n\n",
    "dfe = pd.concat([df_topn, df_botn], ignore_index=True)\n",
    "dfe.sort_values(by=['mean', ], ascending=False, inplace=True)\n",
    "codes = [str(c) for c in dfe['code'].values]\n",
    "scores = dfe['mean'].values\n",
    "# print('lower(n)+higher codes(n): {}'.format(codes))\n",
    "# print('scores: {}'.format(scores))\n",
    "print(dfe)\n",
    "\n",
    "# sns.barplot(x=\"total\", y=\"abbrev\", data=crashes,\n",
    "#             label=\"Total\", color=\"b\")\n",
    "\n",
    "# --------------------\n",
    "# ax = sns.barplot(x='mean', y='code', data=df_botn)\n",
    "# print(\"-------------------------\\n\\n\")\n",
    "# print(\"> dtype: {}\".format(df_botn.dtypes))\n",
    "# print(df_botn.head(10))\n",
    "\n",
    "# dfe = dfe[['mean', 'code']]\n",
    "# dfe.plot(kind='bar')\n",
    "\n",
    "sns.barplot(x='mean', y='code', data=dfe, order=dfe['code'], # order has to be specified; even if already sorted!!!\n",
    "            label=\"LOINC\", color=\"b\", orient='h')\n",
    "\n",
    "# ax = sns.barplot(x='mean', y='code', data=df)\n",
    "\n",
    "# ax.set_xlabel('Fmax Score')\n",
    "# ax.set_ylabel('LOINC')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
